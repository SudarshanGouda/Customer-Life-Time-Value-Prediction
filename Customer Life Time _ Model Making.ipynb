{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ab7d84",
   "metadata": {},
   "source": [
    "# Predictive Maintenance aircraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14445bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e6dca",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7717a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_pickle(\"./X_train.pkl\")\n",
    "X_test=pd.read_pickle(\"./X_test.pkl\")\n",
    "y_train=pd.read_pickle(\"./y_train.pkl\")\n",
    "y_test=pd.read_pickle(\"./y_test.pkl\")\n",
    "\n",
    "X=pd.read_pickle(\"./X.pkl\")\n",
    "y=pd.read_pickle(\"./y.pkl\")\n",
    "df=pd.read_pickle(\"./df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60792a62",
   "metadata": {},
   "source": [
    "## Standardization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a533fe",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bfcf3f",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ba406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919c2549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51020.54845084059\n",
      "6822890878.509039\n",
      "0.15147064926758758\n"
     ]
    }
   ],
   "source": [
    "M1= LinearRegression()\n",
    "M1.fit(X_train,y_train)\n",
    "P1= M1.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error,mean_absolute_error,r2_score\n",
    "print(mean_absolute_error(y_test,P1))\n",
    "print(mean_squared_error(y_test,P1))\n",
    "print(r2_score(y_test,P1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d9327",
   "metadata": {},
   "source": [
    "### Linear Regression digree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97295862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8ad848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50042.72848223534\n",
      "6770791309.190201\n",
      "0.1579500162272438\n"
     ]
    }
   ],
   "source": [
    "M2 = make_pipeline(PolynomialFeatures(degree=2),LinearRegression())\n",
    "M2.fit(X_train,y_train)\n",
    "P2=M2.predict(X_test)\n",
    "\n",
    "\n",
    "print(mean_absolute_error(y_test,P2))\n",
    "print(mean_squared_error(y_test,P2))\n",
    "print(r2_score(y_test,P2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd9143",
   "metadata": {},
   "source": [
    "### Linear Regression digree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb465b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50064.45206785414\n",
      "6773388154.083041\n",
      "0.15762705941170763\n"
     ]
    }
   ],
   "source": [
    "M3 = make_pipeline(PolynomialFeatures(degree=3),LinearRegression())\n",
    "M3.fit(X_train,y_train)\n",
    "P3=M3.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P3))\n",
    "print(mean_squared_error(y_test,P3))\n",
    "print(r2_score(y_test,P3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f8b8a2",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aebd11c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51020.24969356149\n",
      "6822891001.064066\n",
      "0.15147063402602223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "M4 = Ridge()\n",
    "M4.fit(X_train,y_train)\n",
    "P4= M4.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P4))\n",
    "print(mean_squared_error(y_test,P4))\n",
    "print(r2_score(y_test,P4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce93127",
   "metadata": {},
   "source": [
    "### Ridge Regression digree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3a40b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50042.71417277376\n",
      "6770785057.671682\n",
      "0.15795079369782694\n"
     ]
    }
   ],
   "source": [
    "M5 = make_pipeline(PolynomialFeatures(degree=2),Ridge())\n",
    "M5.fit(X_train,y_train)\n",
    "P5= M5.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P5))\n",
    "print(mean_squared_error(y_test,P5))\n",
    "print(r2_score(y_test,P5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64469637",
   "metadata": {},
   "source": [
    "### Ridge Regression digree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b8a069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50064.91224257052\n",
      "6773614712.612826\n",
      "0.15759888344266393\n"
     ]
    }
   ],
   "source": [
    "M6 = make_pipeline(PolynomialFeatures(degree=3),Ridge())\n",
    "M6.fit(X_train,y_train)\n",
    "P6= M6.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P6))\n",
    "print(mean_squared_error(y_test,P6))\n",
    "print(r2_score(y_test,P6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f2cd6f",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a1c37d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51019.86432252958\n",
      "6822878230.543127\n",
      "0.1514722222328444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "M7 = Lasso()\n",
    "M7.fit(X_train,y_train)\n",
    "P7 = M7.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P7))\n",
    "print(mean_squared_error(y_test,P7))\n",
    "print(r2_score(y_test,P7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f4cf9",
   "metadata": {},
   "source": [
    "### Lasso 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aec2b12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50042.782360916855\n",
      "6770738960.933772\n",
      "0.15795652652219516\n"
     ]
    }
   ],
   "source": [
    "M8 = make_pipeline(PolynomialFeatures(degree=2),Lasso())\n",
    "M8.fit(X_train,y_train)\n",
    "P8= M8.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P8))\n",
    "print(mean_squared_error(y_test,P8))\n",
    "print(r2_score(y_test,P8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ffff55",
   "metadata": {},
   "source": [
    "### Lasso 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b29019a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50062.555721392164\n",
      "6773787380.981288\n",
      "0.15757740952769272\n"
     ]
    }
   ],
   "source": [
    "M9 = make_pipeline(PolynomialFeatures(degree=3),Lasso())\n",
    "M9.fit(X_train,y_train)\n",
    "P9= M9.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P9))\n",
    "print(mean_squared_error(y_test,P9))\n",
    "print(r2_score(y_test,P9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee25fd",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4396ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a263d031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6269739612853173.0\n",
      "6.147963179384557e+31\n",
      "-7.645919153363234e+21\n"
     ]
    }
   ],
   "source": [
    "M10 = SGDRegressor(max_iter=2000, tol=1e-3)\n",
    "M10.fit(X_train,y_train)\n",
    "P10= M10.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P10))\n",
    "print(mean_squared_error(y_test,P10))\n",
    "print(r2_score(y_test,P10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb0d0ac",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "712a5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e45228e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67287.65231887571\n",
      "14064668939.556496\n",
      "118594.55695585905\n",
      "-0.7491536382531332\n"
     ]
    }
   ],
   "source": [
    "M11 = DecisionTreeRegressor()\n",
    "M11.fit(X_train,y_train)\n",
    "P11 = M11.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P11))\n",
    "print(mean_squared_error(y_test,P11))\n",
    "print(np.sqrt(mean_squared_error(y_test,P11)))\n",
    "print(r2_score(y_test,P11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85606184",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1ee5c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54900.68957060498\n",
      "7846646948.521279\n",
      "88581.30134809084\n",
      "0.024151146601632423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "M12 = RandomForestRegressor()\n",
    "\n",
    "M12.fit(X_train,y_train)\n",
    "P12= M12.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P12))\n",
    "print(mean_squared_error(y_test,P12))\n",
    "print(np.sqrt(mean_squared_error(y_test,P12)))\n",
    "print(r2_score(y_test,P12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b86a7",
   "metadata": {},
   "source": [
    "### AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45f35ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85483.23147318505\n",
      "10984278036.741926\n",
      "104805.90649740084\n",
      "-0.36606058586381307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "M13 =AdaBoostRegressor()\n",
    "\n",
    "M13.fit(X_train,y_train)\n",
    "P13 =M13.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P13))\n",
    "print(mean_squared_error(y_test,P13))\n",
    "print(np.sqrt(mean_squared_error(y_test,P13)))\n",
    "print(r2_score(y_test,P13))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d94de",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "980e6bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49959.64518437472\n",
      "6763003213.99763\n",
      "82237.48059125857\n",
      "0.15891858328699415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "M14 = GradientBoostingRegressor()\n",
    "\n",
    "M14.fit(X_train,y_train)\n",
    "P14 = M14.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P14))\n",
    "print(mean_squared_error(y_test,P14))\n",
    "print(np.sqrt(mean_squared_error(y_test,P14)))\n",
    "print(r2_score(y_test,P14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bb539",
   "metadata": {},
   "source": [
    "### KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a0c4610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65686.70155932203\n",
      "11193367722.533695\n",
      "105798.71323666321\n",
      "-0.39206404077594903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "M15 = KNeighborsRegressor(n_neighbors=2)\n",
    "\n",
    "M15.fit(X_train,y_train)\n",
    "\n",
    "P15= M15.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P15))\n",
    "print(mean_squared_error(y_test,P15))\n",
    "print(np.sqrt(mean_squared_error(y_test,P15)))\n",
    "print(r2_score(y_test,P15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c04bd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_Mat=[]\n",
    "for i in range (1,50):\n",
    "    knn=KNeighborsRegressor(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    predict_i=knn.predict(X_test)\n",
    "    error_Mat.append(r2_score(y_test,predict_i))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,50),error_Mat,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43e5d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55562.96172203389\n",
      "7760129656.164579\n",
      "88091.59810200165\n",
      "0.03491087634343348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "M15 = KNeighborsRegressor(n_neighbors=50)\n",
    "\n",
    "M15.fit(X_train,y_train)\n",
    "\n",
    "P15= M15.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P15))\n",
    "print(mean_squared_error(y_test,P15))\n",
    "print(np.sqrt(mean_squared_error(y_test,P15)))\n",
    "print(r2_score(y_test,P15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02565c20",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb02d2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48092.78293020672\n",
      "8959075025.058775\n",
      "94652.39048782008\n",
      "-0.11419605700000846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "M16= SVR()\n",
    "\n",
    "M16.fit(X_train,y_train)\n",
    "\n",
    "P16= M16.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P16))\n",
    "print(mean_squared_error(y_test,P16))\n",
    "print(np.sqrt(mean_squared_error(y_test,P16)))\n",
    "print(r2_score(y_test,P16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ef26f",
   "metadata": {},
   "source": [
    "### Neural Network Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48be8d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6d7d2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54392.651499276406\n",
      "6937573461.511806\n",
      "83292.0972332418\n",
      "0.13720814098064305\n"
     ]
    }
   ],
   "source": [
    "M17= MLPRegressor(hidden_layer_sizes=(200,))\n",
    "\n",
    "M17.fit(X_train,y_train)\n",
    "\n",
    "P17= M17.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P17))\n",
    "print(mean_squared_error(y_test,P17))\n",
    "print(np.sqrt(mean_squared_error(y_test,P17)))\n",
    "print(r2_score(y_test,P17))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f35e36",
   "metadata": {},
   "source": [
    "### Histogram Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fdd55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3281d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49940.9376242784\n",
      "6776358348.306075\n",
      "82318.63913055217\n",
      "0.15725767097790477\n"
     ]
    }
   ],
   "source": [
    "M18= HistGradientBoostingRegressor()\n",
    "\n",
    "M18.fit(X_train,y_train)\n",
    "\n",
    "P18= M18.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P18))\n",
    "print(mean_squared_error(y_test,P18))\n",
    "print(np.sqrt(mean_squared_error(y_test,P18)))\n",
    "print(r2_score(y_test,P18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566ae617",
   "metadata": {},
   "source": [
    "### XGB Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50385db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRFRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddf1d227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50036.121994041314\n",
      "6772454460.779197\n",
      "82294.92366348727\n",
      "0.15774317825150763\n"
     ]
    }
   ],
   "source": [
    "M19= XGBRFRegressor()\n",
    "\n",
    "M19.fit(X_train,y_train)\n",
    "\n",
    "P19= M19.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P19))\n",
    "print(mean_squared_error(y_test,P19))\n",
    "print(np.sqrt(mean_squared_error(y_test,P19)))\n",
    "print(r2_score(y_test,P19))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3f2b27",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b002c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe3fd170",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49983.81931520472\n",
      "6795430357.165709\n",
      "82434.4003263547\n",
      "0.15488577912399848\n"
     ]
    }
   ],
   "source": [
    "M20= LGBMRegressor()\n",
    "\n",
    "M20.fit(X_train,y_train)\n",
    "\n",
    "P20= M20.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P20))\n",
    "print(mean_squared_error(y_test,P20))\n",
    "print(np.sqrt(mean_squared_error(y_test,P20)))\n",
    "print(r2_score(y_test,P20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f9da5b",
   "metadata": {},
   "source": [
    "### CAT Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcee8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3667035",
   "metadata": {},
   "outputs": [],
   "source": [
    "M21= CatBoostRegressor(verbose=0)\n",
    "\n",
    "M21.fit(X_train,y_train)\n",
    "\n",
    "P21= M21.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af92ebc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50445.90077033555\n",
      "6874361646.939579\n",
      "82911.77025573378\n",
      "0.14506948317893853\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test,P21))\n",
    "print(mean_squared_error(y_test,P21))\n",
    "print(np.sqrt(mean_squared_error(y_test,P21)))\n",
    "print(r2_score(y_test,P21))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6fbbe5",
   "metadata": {},
   "source": [
    "### BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec271334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "428fc349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56800.5523433578\n",
      "8449028777.9189\n",
      "91918.59865075674\n",
      "-0.05076411610640319\n"
     ]
    }
   ],
   "source": [
    "M22= BaggingRegressor()\n",
    "\n",
    "M22.fit(X_train,y_train)\n",
    "\n",
    "P22= M22.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P22))\n",
    "print(mean_squared_error(y_test,P22))\n",
    "print(np.sqrt(mean_squared_error(y_test,P22)))\n",
    "print(r2_score(y_test,P22))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d12afc6",
   "metadata": {},
   "source": [
    "### NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebf93d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e22c53b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50401.87474117359\n",
      "8365424768.949562\n",
      "91462.69605117467\n",
      "-0.040366697077934166\n"
     ]
    }
   ],
   "source": [
    "M23= NuSVR()\n",
    "\n",
    "M23.fit(X_train,y_train)\n",
    "\n",
    "P23= M23.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P23))\n",
    "print(mean_squared_error(y_test,P23))\n",
    "print(np.sqrt(mean_squared_error(y_test,P23)))\n",
    "print(r2_score(y_test,P23))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179fc5f",
   "metadata": {},
   "source": [
    "### ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7355d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cee8c183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58615.544242832126\n",
      "9824346838.230244\n",
      "99117.84318794595\n",
      "-0.2218056528313117\n"
     ]
    }
   ],
   "source": [
    "M24= ExtraTreesRegressor()\n",
    "\n",
    "M24.fit(X_train,y_train)\n",
    "\n",
    "P24= M24.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P24))\n",
    "print(mean_squared_error(y_test,P24))\n",
    "print(np.sqrt(mean_squared_error(y_test,P24)))\n",
    "print(r2_score(y_test,P24))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6df6e48",
   "metadata": {},
   "source": [
    "### PoissonRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82e8a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PoissonRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ce5ac55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58647.44995999796\n",
      "9837371186.145676\n",
      "99183.52275527258\n",
      "-0.22342542686510214\n"
     ]
    }
   ],
   "source": [
    "M25= ExtraTreesRegressor()\n",
    "\n",
    "M25.fit(X_train,y_train)\n",
    "\n",
    "P25= M25.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P25))\n",
    "print(mean_squared_error(y_test,P25))\n",
    "print(np.sqrt(mean_squared_error(y_test,P25)))\n",
    "print(r2_score(y_test,P25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593c4eb",
   "metadata": {},
   "source": [
    "### HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40f80ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16db70c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44189.07689888529\n",
      "7653325801.035021\n",
      "87483.28869581333\n",
      "0.04819354603030479\n"
     ]
    }
   ],
   "source": [
    "M26= HuberRegressor()\n",
    "\n",
    "M26.fit(X_train,y_train)\n",
    "\n",
    "P26= M26.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P26))\n",
    "print(mean_squared_error(y_test,P26))\n",
    "print(np.sqrt(mean_squared_error(y_test,P26)))\n",
    "print(r2_score(y_test,P26))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9bb4c5",
   "metadata": {},
   "source": [
    "### RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39ee6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c32cbac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51012.537516947195\n",
      "6822834733.618029\n",
      "82600.45238143692\n",
      "0.15147763173129158\n"
     ]
    }
   ],
   "source": [
    "M27= RidgeCV()\n",
    "\n",
    "M27.fit(X_train,y_train)\n",
    "\n",
    "P27= M27.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P27))\n",
    "print(mean_squared_error(y_test,P27))\n",
    "print(np.sqrt(mean_squared_error(y_test,P27)))\n",
    "print(r2_score(y_test,P27))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774a3e0",
   "metadata": {},
   "source": [
    "### BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2af1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13a2c80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51015.86524495908\n",
      "6822894187.841389\n",
      "82600.81227107509\n",
      "0.15147023770221446\n"
     ]
    }
   ],
   "source": [
    "M28= BayesianRidge()\n",
    "\n",
    "M28.fit(X_train,y_train)\n",
    "\n",
    "P28= M28.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P28))\n",
    "print(mean_squared_error(y_test,P28))\n",
    "print(np.sqrt(mean_squared_error(y_test,P28)))\n",
    "print(r2_score(y_test,P28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e60ea",
   "metadata": {},
   "source": [
    "### ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29334cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7449f21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56328.44301276543\n",
      "7890549541.208973\n",
      "88828.76528022312\n",
      "0.0186911972733943\n"
     ]
    }
   ],
   "source": [
    "#M29= ElasticNetCV()\n",
    "M29 = make_pipeline(PolynomialFeatures(degree=2),ElasticNetCV())\n",
    "M29.fit(X_train,y_train)\n",
    "\n",
    "P29= M29.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P29))\n",
    "print(mean_squared_error(y_test,P29))\n",
    "print(np.sqrt(mean_squared_error(y_test,P29)))\n",
    "print(r2_score(y_test,P29))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85681198",
   "metadata": {},
   "source": [
    "### TransformedTargetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f919776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f9634b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56328.44301276543\n",
      "7890549541.208973\n",
      "88828.76528022312\n",
      "0.0186911972733943\n"
     ]
    }
   ],
   "source": [
    "M30=TransformedTargetRegressor(regressor=M29)\n",
    "M30.fit(X_train,y_train)\n",
    "\n",
    "P30= M30.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P30))\n",
    "print(mean_squared_error(y_test,P30))\n",
    "print(np.sqrt(mean_squared_error(y_test,P30)))\n",
    "print(r2_score(y_test,P30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfacf90",
   "metadata": {},
   "source": [
    "### TweedieRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "460e8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import TweedieRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba6ac905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54011.48658490489\n",
      "7479856961.021101\n",
      "86486.16629855378\n",
      "0.06976701170787425\n"
     ]
    }
   ],
   "source": [
    "M31=TweedieRegressor()\n",
    "M31.fit(X_train,y_train)\n",
    "\n",
    "P31= M31.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P31))\n",
    "print(mean_squared_error(y_test,P31))\n",
    "print(np.sqrt(mean_squared_error(y_test,P31)))\n",
    "print(r2_score(y_test,P31))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d340945",
   "metadata": {},
   "source": [
    "### RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9712e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d84ecb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47134.47921015524\n",
      "8718238037.132189\n",
      "93371.50548819585\n",
      "-0.08424434640745204\n"
     ]
    }
   ],
   "source": [
    "M32=RANSACRegressor()\n",
    "M32.fit(X_train,y_train)\n",
    "\n",
    "P32= M32.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P32))\n",
    "print(mean_squared_error(y_test,P32))\n",
    "print(np.sqrt(mean_squared_error(y_test,P32)))\n",
    "print(r2_score(y_test,P32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6284a4b",
   "metadata": {},
   "source": [
    "### OrthogonalMatchingPursuitCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f83ca35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import OrthogonalMatchingPursuitCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "add47e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50980.683465468115\n",
      "6838536435.96691\n",
      "82695.44386462237\n",
      "0.14952488830673294\n"
     ]
    }
   ],
   "source": [
    "M33=OrthogonalMatchingPursuitCV()\n",
    "M33.fit(X_train,y_train)\n",
    "\n",
    "P33= M33.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P33))\n",
    "print(mean_squared_error(y_test,P33))\n",
    "print(np.sqrt(mean_squared_error(y_test,P33)))\n",
    "print(r2_score(y_test,P33))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af2fe1",
   "metadata": {},
   "source": [
    "### PassiveAggressiveRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7dedcff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68d333d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79859.7924405605\n",
      "10930098967.277716\n",
      "104547.11362480417\n",
      "-0.35932260170807084\n"
     ]
    }
   ],
   "source": [
    "M34=PassiveAggressiveRegressor()\n",
    "M34.fit(X_train,y_train)\n",
    "\n",
    "P34= M34.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P34))\n",
    "print(mean_squared_error(y_test,P34))\n",
    "print(np.sqrt(mean_squared_error(y_test,P34)))\n",
    "print(r2_score(y_test,P34))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d121ba",
   "metadata": {},
   "source": [
    "## All at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "976f83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=['Linear Regression','Linear Regression digree 2','Linear Regression digree 3','Ridge Regression',\n",
    "      'Ridge Regression digree 2','Ridge Regression digree 3','Lasso','Lasso digree 2','Lasso digree 3','SGDRegressor',\n",
    "     'Decision Tree Regressor','Random Forest Regressor','AdaBoost Regressor','Gradient Boosting Regressor','KNN Regressor',\n",
    "      'Support Vector Machine','Neural Network Regression','Histogram Boosting','XGB Boosting','Light GBM','CAT Boosting',\n",
    "      'BaggingRegressor','NuSVR','ExtraTreesRegressor','PoissonRegressor','HuberRegressor',\n",
    "      'RidgeCV','BayesianRidge','ElasticNetCV','TransformedTargetRegressor','TweedieRegressor',\n",
    "      'RANSACRegressor','OrthogonalMatchingPursuitCV','PassiveAggressiveRegressor']\n",
    "clfs= [M1,M2,M3,M4,M5,M6,M7,M8,M9,M10,M11,M12,M13,M14,M15,M16,M17,M18,M19,M20,M21,M22,M23,M24,M25,M26,M27,M28,M29,M30,\n",
    "       M31,M32,M33,M34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fff7ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in clfs:\n",
    "    i.fit(X_train,y_train)\n",
    "    r2=r2_score(y_test, i.predict(X_test))\n",
    "    results.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61c731c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Regressor</th>\n",
       "      <td>1.589184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso digree 2</th>\n",
       "      <td>1.579565e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression digree 2</th>\n",
       "      <td>1.579508e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression digree 2</th>\n",
       "      <td>1.579500e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB Boosting</th>\n",
       "      <td>1.577432e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression digree 3</th>\n",
       "      <td>1.576271e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression digree 3</th>\n",
       "      <td>1.575989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso digree 3</th>\n",
       "      <td>1.575774e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Histogram Boosting</th>\n",
       "      <td>1.570953e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Light GBM</th>\n",
       "      <td>1.548858e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>1.514776e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.514722e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>1.514706e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>1.514706e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>1.514702e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>1.495249e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network Regression</th>\n",
       "      <td>1.470646e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT Boosting</th>\n",
       "      <td>1.450695e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>6.976701e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>4.819355e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Regressor</th>\n",
       "      <td>3.491088e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Regressor</th>\n",
       "      <td>2.361957e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>1.869120e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>1.869120e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>-4.036670e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>-4.169898e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>-6.606126e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>-1.141961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>-1.358731e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>-2.204992e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>-2.210963e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Regressor</th>\n",
       "      <td>-3.785244e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Regressor</th>\n",
       "      <td>-7.508566e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>-1.474595e+20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       R2\n",
       "Gradient Boosting Regressor  1.589184e-01\n",
       "Lasso digree 2               1.579565e-01\n",
       "Ridge Regression digree 2    1.579508e-01\n",
       "Linear Regression digree 2   1.579500e-01\n",
       "XGB Boosting                 1.577432e-01\n",
       "Linear Regression digree 3   1.576271e-01\n",
       "Ridge Regression digree 3    1.575989e-01\n",
       "Lasso digree 3               1.575774e-01\n",
       "Histogram Boosting           1.570953e-01\n",
       "Light GBM                    1.548858e-01\n",
       "RidgeCV                      1.514776e-01\n",
       "Lasso                        1.514722e-01\n",
       "Linear Regression            1.514706e-01\n",
       "Ridge Regression             1.514706e-01\n",
       "BayesianRidge                1.514702e-01\n",
       "OrthogonalMatchingPursuitCV  1.495249e-01\n",
       "Neural Network Regression    1.470646e-01\n",
       "CAT Boosting                 1.450695e-01\n",
       "TweedieRegressor             6.976701e-02\n",
       "HuberRegressor               4.819355e-02\n",
       "KNN Regressor                3.491088e-02\n",
       "Random Forest Regressor      2.361957e-02\n",
       "TransformedTargetRegressor   1.869120e-02\n",
       "ElasticNetCV                 1.869120e-02\n",
       "NuSVR                       -4.036670e-02\n",
       "BaggingRegressor            -4.169898e-02\n",
       "RANSACRegressor             -6.606126e-02\n",
       "Support Vector Machine      -1.141961e-01\n",
       "PassiveAggressiveRegressor  -1.358731e-01\n",
       "PoissonRegressor            -2.204992e-01\n",
       "ExtraTreesRegressor         -2.210963e-01\n",
       "AdaBoost Regressor          -3.785244e-01\n",
       "Decision Tree Regressor     -7.508566e-01\n",
       "SGDRegressor                -1.474595e+20"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score= pd.DataFrame(results,index=Name)\n",
    "score.columns=['R2']\n",
    "score.sort_values(by='R2',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f380ad",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f6ab81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a39ec0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=KFold(n_splits=5,shuffle=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c112d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=KFold(n_splits=5,shuffle=False, random_state=None)\n",
    "results_mean=[]\n",
    "\n",
    "for i in clfs:\n",
    "    csv=cross_val_score(i,X_train,y_train,cv=kfold)\n",
    "    mean_score=csv.mean()\n",
    "    results_mean.append(mean_score)\n",
    "\n",
    "score= pd.DataFrame(results_mean,index=Name)\n",
    "score.columns=['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68b13964",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lasso digree 2</th>\n",
       "      <td>1.585448e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression digree 2</th>\n",
       "      <td>1.585400e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression digree 2</th>\n",
       "      <td>1.585393e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Regressor</th>\n",
       "      <td>1.576500e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso digree 3</th>\n",
       "      <td>1.574604e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression digree 3</th>\n",
       "      <td>1.573748e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB Boosting</th>\n",
       "      <td>1.573492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression digree 3</th>\n",
       "      <td>1.573427e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Histogram Boosting</th>\n",
       "      <td>1.552947e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Light GBM</th>\n",
       "      <td>1.520073e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>1.511508e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>1.511507e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>1.511507e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.511506e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>1.491270e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT Boosting</th>\n",
       "      <td>1.450697e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network Regression</th>\n",
       "      <td>1.365237e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>7.170858e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>3.872250e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Regressor</th>\n",
       "      <td>3.834442e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>3.323544e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>2.053621e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>2.053621e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Regressor</th>\n",
       "      <td>1.707727e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>-4.391301e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>-4.885528e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>-8.528156e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>-1.181115e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Regressor</th>\n",
       "      <td>-1.252872e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>-2.351611e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>-2.377841e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Regressor</th>\n",
       "      <td>-7.373149e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>-4.290851e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>-2.727911e+21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy\n",
       "Lasso digree 2               1.585448e-01\n",
       "Ridge Regression digree 2    1.585400e-01\n",
       "Linear Regression digree 2   1.585393e-01\n",
       "Gradient Boosting Regressor  1.576500e-01\n",
       "Lasso digree 3               1.574604e-01\n",
       "Ridge Regression digree 3    1.573748e-01\n",
       "XGB Boosting                 1.573492e-01\n",
       "Linear Regression digree 3   1.573427e-01\n",
       "Histogram Boosting           1.552947e-01\n",
       "Light GBM                    1.520073e-01\n",
       "RidgeCV                      1.511508e-01\n",
       "Ridge Regression             1.511507e-01\n",
       "Linear Regression            1.511507e-01\n",
       "Lasso                        1.511506e-01\n",
       "OrthogonalMatchingPursuitCV  1.491270e-01\n",
       "CAT Boosting                 1.450697e-01\n",
       "Neural Network Regression    1.365237e-01\n",
       "TweedieRegressor             7.170858e-02\n",
       "HuberRegressor               3.872250e-02\n",
       "KNN Regressor                3.834442e-02\n",
       "BayesianRidge                3.323544e-02\n",
       "TransformedTargetRegressor   2.053621e-02\n",
       "ElasticNetCV                 2.053621e-02\n",
       "Random Forest Regressor      1.707727e-02\n",
       "NuSVR                       -4.391301e-02\n",
       "BaggingRegressor            -4.885528e-02\n",
       "RANSACRegressor             -8.528156e-02\n",
       "Support Vector Machine      -1.181115e-01\n",
       "AdaBoost Regressor          -1.252872e-01\n",
       "ExtraTreesRegressor         -2.351611e-01\n",
       "PoissonRegressor            -2.377841e-01\n",
       "Decision Tree Regressor     -7.373149e-01\n",
       "PassiveAggressiveRegressor  -4.290851e+00\n",
       "SGDRegressor                -2.727911e+21"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.sort_values(by='Accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9413e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59892, 11)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3108911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5aa445b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(15,activation='relu'))\n",
    "\n",
    "model.add(Dense(14,activation='relu'))\n",
    "\n",
    "model.add(Dense(14,activation='relu'))\n",
    "\n",
    "model.add(Dense(14,activation='relu'))\n",
    "\n",
    "model.add(Dense(12,activation='relu'))\n",
    "\n",
    "model.add(Dense(10,activation='relu'))\n",
    "\n",
    "model.add(Dense(6,activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e06998b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1872/1872 [==============================] - 9s 3ms/step - loss: 9589314560.0000 - mse: 9589314560.0000 - val_loss: 8689823744.0000 - val_mse: 8689823744.0000\n",
      "Epoch 2/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 8936580096.0000 - mse: 8936580096.0000 - val_loss: 8648532992.0000 - val_mse: 8648532992.0000\n",
      "Epoch 3/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 8898123776.0000 - mse: 8898123776.0000 - val_loss: 8604922880.0000 - val_mse: 8604922880.0000\n",
      "Epoch 4/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 8853136384.0000 - mse: 8853136384.0000 - val_loss: 8609601536.0000 - val_mse: 8609601536.0000\n",
      "Epoch 5/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 8829835264.0000 - mse: 8829835264.0000 - val_loss: 8557625856.0000 - val_mse: 8557625856.0000\n",
      "Epoch 6/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 8814937088.0000 - mse: 8814937088.0000 - val_loss: 8540738560.0000 - val_mse: 8540738560.0000\n",
      "Epoch 7/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 8801873920.0000 - mse: 8801873920.0000 - val_loss: 8520680448.0000 - val_mse: 8520680448.0000\n",
      "Epoch 8/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 8778226688.0000 - mse: 8778226688.0000 - val_loss: 8504328704.0000 - val_mse: 8504328704.0000\n",
      "Epoch 9/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 8733784064.0000 - mse: 8733784064.0000 - val_loss: 8511917568.0000 - val_mse: 8511917568.0000\n",
      "Epoch 10/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 8619545600.0000 - mse: 8619545600.0000 - val_loss: 8172106752.0000 - val_mse: 8172106752.0000\n",
      "Epoch 11/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 8096365568.0000 - mse: 8096365568.0000 - val_loss: 7531527168.0000 - val_mse: 7531527168.0000\n",
      "Epoch 12/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7802971648.0000 - mse: 7802971648.0000 - val_loss: 7449243136.0000 - val_mse: 7449243136.0000\n",
      "Epoch 13/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7723177472.0000 - mse: 7723177472.0000 - val_loss: 7523495936.0000 - val_mse: 7523495936.0000\n",
      "Epoch 14/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7650156032.0000 - mse: 7650156032.0000 - val_loss: 7313792512.0000 - val_mse: 7313792512.0000\n",
      "Epoch 15/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7603968000.0000 - mse: 7603968000.0000 - val_loss: 7218594304.0000 - val_mse: 7218594304.0000\n",
      "Epoch 16/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7514675712.0000 - mse: 7514675712.0000 - val_loss: 7418074624.0000 - val_mse: 7418074624.0000\n",
      "Epoch 17/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7465004544.0000 - mse: 7465004544.0000 - val_loss: 7116430848.0000 - val_mse: 7116430848.0000\n",
      "Epoch 18/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7415500800.0000 - mse: 7415500800.0000 - val_loss: 7088558080.0000 - val_mse: 7088558080.0000\n",
      "Epoch 19/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7371375616.0000 - mse: 7371375616.0000 - val_loss: 7515197952.0000 - val_mse: 7515197952.0000\n",
      "Epoch 20/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7317039616.0000 - mse: 7317039616.0000 - val_loss: 7015355392.0000 - val_mse: 7015355392.0000\n",
      "Epoch 21/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7301334016.0000 - mse: 7301334016.0000 - val_loss: 6950705664.0000 - val_mse: 6950705664.0000\n",
      "Epoch 22/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7253018112.0000 - mse: 7253018112.0000 - val_loss: 6942840832.0000 - val_mse: 6942840832.0000\n",
      "Epoch 23/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7255257600.0000 - mse: 7255257600.0000 - val_loss: 6953236992.0000 - val_mse: 6953236992.0000\n",
      "Epoch 24/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7281185280.0000 - mse: 7281185280.0000 - val_loss: 6978766336.0000 - val_mse: 6978766336.0000\n",
      "Epoch 25/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7232197120.0000 - mse: 7232197120.0000 - val_loss: 6871574528.0000 - val_mse: 6871574528.0000\n",
      "Epoch 26/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7255799808.0000 - mse: 7255799808.0000 - val_loss: 6988995584.0000 - val_mse: 6988995584.0000\n",
      "Epoch 27/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7216481792.0000 - mse: 7216481792.0000 - val_loss: 6864093184.0000 - val_mse: 6864093184.0000\n",
      "Epoch 28/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7216666624.0000 - mse: 7216666624.0000 - val_loss: 7434789888.0000 - val_mse: 7434789888.0000\n",
      "Epoch 29/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7217383424.0000 - mse: 7217383424.0000 - val_loss: 7607346688.0000 - val_mse: 7607346688.0000\n",
      "Epoch 30/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7204877312.0000 - mse: 7204877312.0000 - val_loss: 6882021376.0000 - val_mse: 6882021376.0000\n",
      "Epoch 31/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7212042752.0000 - mse: 7212042752.0000 - val_loss: 6860427776.0000 - val_mse: 6860427776.0000\n",
      "Epoch 32/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7187365888.0000 - mse: 7187365888.0000 - val_loss: 8086871040.0000 - val_mse: 8086871040.0000\n",
      "Epoch 33/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7175420928.0000 - mse: 7175420928.0000 - val_loss: 7011650560.0000 - val_mse: 7011650560.0000\n",
      "Epoch 34/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7174354432.0000 - mse: 7174354432.0000 - val_loss: 6836183040.0000 - val_mse: 6836183040.0000\n",
      "Epoch 35/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7177520128.0000 - mse: 7177520128.0000 - val_loss: 7033049088.0000 - val_mse: 7033049088.0000\n",
      "Epoch 36/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7197329920.0000 - mse: 7197329920.0000 - val_loss: 7003225088.0000 - val_mse: 7003225088.0000\n",
      "Epoch 37/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7171227136.0000 - mse: 7171227136.0000 - val_loss: 7203321344.0000 - val_mse: 7203321344.0000\n",
      "Epoch 38/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7162307072.0000 - mse: 7162307072.0000 - val_loss: 6926535168.0000 - val_mse: 6926535168.0000\n",
      "Epoch 39/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7199208960.0000 - mse: 7199208960.0000 - val_loss: 6913046528.0000 - val_mse: 6913046528.0000\n",
      "Epoch 40/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7164255232.0000 - mse: 7164255232.0000 - val_loss: 6908893696.0000 - val_mse: 6908893696.0000\n",
      "Epoch 41/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7161180672.0000 - mse: 7161180672.0000 - val_loss: 6844393984.0000 - val_mse: 6844393984.0000\n",
      "Epoch 42/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7155087872.0000 - mse: 7155087872.0000 - val_loss: 6903372800.0000 - val_mse: 6903372800.0000\n",
      "Epoch 43/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7184718848.0000 - mse: 7184718848.0000 - val_loss: 6844151296.0000 - val_mse: 6844151296.0000\n",
      "Epoch 44/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7174744064.0000 - mse: 7174744064.0000 - val_loss: 6883276800.0000 - val_mse: 6883276800.0000\n",
      "Epoch 45/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7136175104.0000 - mse: 7136175104.0000 - val_loss: 7080614912.0000 - val_mse: 7080614912.0000\n",
      "Epoch 46/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7152305664.0000 - mse: 7152305664.0000 - val_loss: 6817369600.0000 - val_mse: 6817369600.0000\n",
      "Epoch 47/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7133407232.0000 - mse: 7133407232.0000 - val_loss: 7012559872.0000 - val_mse: 7012559872.0000\n",
      "Epoch 48/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7151030784.0000 - mse: 7151030784.0000 - val_loss: 6825412096.0000 - val_mse: 6825412096.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7156741632.0000 - mse: 7156741632.0000 - val_loss: 6811211776.0000 - val_mse: 6811211776.0000\n",
      "Epoch 50/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7150833152.0000 - mse: 7150833152.0000 - val_loss: 7842914304.0000 - val_mse: 7842914304.0000\n",
      "Epoch 51/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7152752128.0000 - mse: 7152752128.0000 - val_loss: 6871080960.0000 - val_mse: 6871080960.0000\n",
      "Epoch 52/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7146391552.0000 - mse: 7146391552.0000 - val_loss: 7146382336.0000 - val_mse: 7146382336.0000\n",
      "Epoch 53/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7149781504.0000 - mse: 7149781504.0000 - val_loss: 6814291968.0000 - val_mse: 6814291968.0000\n",
      "Epoch 54/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7121535488.0000 - mse: 7121535488.0000 - val_loss: 6848010752.0000 - val_mse: 6848010752.0000\n",
      "Epoch 55/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7153426944.0000 - mse: 7153426944.0000 - val_loss: 6817357824.0000 - val_mse: 6817357824.0000\n",
      "Epoch 56/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7142209536.0000 - mse: 7142209536.0000 - val_loss: 7253849088.0000 - val_mse: 7253849088.0000\n",
      "Epoch 57/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7136907264.0000 - mse: 7136907264.0000 - val_loss: 6977605120.0000 - val_mse: 6977605120.0000\n",
      "Epoch 58/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7127834112.0000 - mse: 7127834112.0000 - val_loss: 6922237440.0000 - val_mse: 6922237440.0000\n",
      "Epoch 59/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7140565504.0000 - mse: 7140565504.0000 - val_loss: 6899375104.0000 - val_mse: 6899375104.0000\n",
      "Epoch 60/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7135883264.0000 - mse: 7135883264.0000 - val_loss: 6840978432.0000 - val_mse: 6840978432.0000\n",
      "Epoch 61/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7125772800.0000 - mse: 7125772800.0000 - val_loss: 7181861376.0000 - val_mse: 7181861376.0000\n",
      "Epoch 62/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7146066944.0000 - mse: 7146066944.0000 - val_loss: 6815993856.0000 - val_mse: 6815993856.0000\n",
      "Epoch 63/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7132723712.0000 - mse: 7132723712.0000 - val_loss: 6817921024.0000 - val_mse: 6817921024.0000\n",
      "Epoch 64/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7112565760.0000 - mse: 7112565760.0000 - val_loss: 6818397184.0000 - val_mse: 6818397184.0000\n",
      "Epoch 65/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7130809344.0000 - mse: 7130809344.0000 - val_loss: 6862896640.0000 - val_mse: 6862896640.0000\n",
      "Epoch 66/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7117123584.0000 - mse: 7117123584.0000 - val_loss: 6866061824.0000 - val_mse: 6866061824.0000\n",
      "Epoch 67/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7152551424.0000 - mse: 7152551424.0000 - val_loss: 7230019072.0000 - val_mse: 7230019072.0000\n",
      "Epoch 68/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7141191168.0000 - mse: 7141191168.0000 - val_loss: 7013700608.0000 - val_mse: 7013700608.0000\n",
      "Epoch 69/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7127012864.0000 - mse: 7127012864.0000 - val_loss: 6823243776.0000 - val_mse: 6823243776.0000\n",
      "Epoch 70/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7110682112.0000 - mse: 7110682112.0000 - val_loss: 6828434944.0000 - val_mse: 6828434944.0000\n",
      "Epoch 71/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7109140992.0000 - mse: 7109140992.0000 - val_loss: 7192574464.0000 - val_mse: 7192574464.0000\n",
      "Epoch 72/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7131127296.0000 - mse: 7131127296.0000 - val_loss: 6887374336.0000 - val_mse: 6887374336.0000\n",
      "Epoch 73/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7118173184.0000 - mse: 7118173184.0000 - val_loss: 6978150400.0000 - val_mse: 6978150400.0000\n",
      "Epoch 74/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7103286784.0000 - mse: 7103286784.0000 - val_loss: 6829448192.0000 - val_mse: 6829448192.0000\n",
      "Epoch 75/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7134978048.0000 - mse: 7134978048.0000 - val_loss: 6850080256.0000 - val_mse: 6850080256.0000\n",
      "Epoch 76/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7135781888.0000 - mse: 7135781888.0000 - val_loss: 6836272128.0000 - val_mse: 6836272128.0000\n",
      "Epoch 77/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7125691392.0000 - mse: 7125691392.0000 - val_loss: 7050259456.0000 - val_mse: 7050259456.0000\n",
      "Epoch 78/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7104512512.0000 - mse: 7104512512.0000 - val_loss: 6859399680.0000 - val_mse: 6859399680.0000\n",
      "Epoch 79/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7115511808.0000 - mse: 7115511808.0000 - val_loss: 6817459712.0000 - val_mse: 6817459712.0000\n",
      "Epoch 80/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7111924224.0000 - mse: 7111924224.0000 - val_loss: 7065501696.0000 - val_mse: 7065501696.0000\n",
      "Epoch 81/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7104013824.0000 - mse: 7104013824.0000 - val_loss: 6905699328.0000 - val_mse: 6905699328.0000\n",
      "Epoch 82/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7094412800.0000 - mse: 7094412800.0000 - val_loss: 7188342272.0000 - val_mse: 7188342272.0000\n",
      "Epoch 83/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7113005056.0000 - mse: 7113005056.0000 - val_loss: 6800243200.0000 - val_mse: 6800243200.0000\n",
      "Epoch 84/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7122843648.0000 - mse: 7122843648.0000 - val_loss: 6811971072.0000 - val_mse: 6811971072.0000\n",
      "Epoch 85/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7120237568.0000 - mse: 7120237568.0000 - val_loss: 6805573120.0000 - val_mse: 6805573120.0000\n",
      "Epoch 86/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7126892032.0000 - mse: 7126892032.0000 - val_loss: 6958258688.0000 - val_mse: 6958258688.0000\n",
      "Epoch 87/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7093964800.0000 - mse: 7093964800.0000 - val_loss: 6893386752.0000 - val_mse: 6893386752.0000\n",
      "Epoch 88/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7106170880.0000 - mse: 7106170880.0000 - val_loss: 6981437440.0000 - val_mse: 6981437440.0000\n",
      "Epoch 89/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7111525376.0000 - mse: 7111525376.0000 - val_loss: 7007156736.0000 - val_mse: 7007156736.0000\n",
      "Epoch 90/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7113604608.0000 - mse: 7113604608.0000 - val_loss: 6855921152.0000 - val_mse: 6855921152.0000\n",
      "Epoch 91/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7086544384.0000 - mse: 7086544384.0000 - val_loss: 6889162752.0000 - val_mse: 6889162752.0000\n",
      "Epoch 92/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7110895104.0000 - mse: 7110895104.0000 - val_loss: 7325755904.0000 - val_mse: 7325755904.0000\n",
      "Epoch 93/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7108400640.0000 - mse: 7108400640.0000 - val_loss: 6866564608.0000 - val_mse: 6866564608.0000\n",
      "Epoch 94/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7095997440.0000 - mse: 7095997440.0000 - val_loss: 7114360320.0000 - val_mse: 7114360320.0000\n",
      "Epoch 95/100\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7104555520.0000 - mse: 7104555520.0000 - val_loss: 6797808128.0000 - val_mse: 6797808128.0000\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 6s 3ms/step - loss: 7088091648.0000 - mse: 7088091648.0000 - val_loss: 6802164736.0000 - val_mse: 6802164736.0000\n",
      "Epoch 97/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7092402176.0000 - mse: 7092402176.0000 - val_loss: 6811005952.0000 - val_mse: 6811005952.0000\n",
      "Epoch 98/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7097003520.0000 - mse: 7097003520.0000 - val_loss: 7241569792.0000 - val_mse: 7241569792.0000\n",
      "Epoch 99/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7098461696.0000 - mse: 7098461696.0000 - val_loss: 7404206592.0000 - val_mse: 7404206592.0000\n",
      "Epoch 100/100\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 7078130688.0000 - mse: 7078130688.0000 - val_loss: 6861074432.0000 - val_mse: 6861074432.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161bb356e50>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d438353b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "922/922 [==============================] - 2s 2ms/step\n",
      "48110.4173116393\n",
      "6861073039.304953\n",
      "0.14672212189310363\n"
     ]
    }
   ],
   "source": [
    "P35=model.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P35))\n",
    "print(mean_squared_error(y_test,P35))\n",
    "print(r2_score(y_test,P35))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f0ce9",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2637fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(15,activation='relu'))\n",
    "\n",
    "model1.add(Dense(14,activation='relu'))\n",
    "\n",
    "model1.add(Dense(14,activation='relu'))\n",
    "\n",
    "model1.add(Dense(14,activation='relu'))\n",
    "\n",
    "model1.add(Dense(12,activation='relu'))\n",
    "\n",
    "model1.add(Dense(10,activation='relu'))\n",
    "\n",
    "model1.add(Dense(6,activation='relu'))\n",
    "\n",
    "model1.add(Dense(1))\n",
    "\n",
    "model1.compile(loss='mse',optimizer='adam',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f1c484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early= EarlyStopping(monitor='val_loss',\n",
    "    patience=25,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08cffc80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "1872/1872 [==============================] - 7s 3ms/step - loss: 17949245440.0000 - mse: 17949245440.0000 - val_loss: 17513533440.0000 - val_mse: 17513533440.0000\n",
      "Epoch 2/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17948639232.0000 - mse: 17948639232.0000 - val_loss: 17513160704.0000 - val_mse: 17513160704.0000\n",
      "Epoch 3/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17948272640.0000 - mse: 17948272640.0000 - val_loss: 17512800256.0000 - val_mse: 17512800256.0000\n",
      "Epoch 4/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17947904000.0000 - mse: 17947904000.0000 - val_loss: 17512452096.0000 - val_mse: 17512452096.0000\n",
      "Epoch 5/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17947545600.0000 - mse: 17947545600.0000 - val_loss: 17512091648.0000 - val_mse: 17512091648.0000\n",
      "Epoch 6/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17947176960.0000 - mse: 17947176960.0000 - val_loss: 17511723008.0000 - val_mse: 17511723008.0000\n",
      "Epoch 7/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17946810368.0000 - mse: 17946810368.0000 - val_loss: 17511364608.0000 - val_mse: 17511364608.0000\n",
      "Epoch 8/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17946451968.0000 - mse: 17946451968.0000 - val_loss: 17511006208.0000 - val_mse: 17511006208.0000\n",
      "Epoch 9/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17946103808.0000 - mse: 17946103808.0000 - val_loss: 17510651904.0000 - val_mse: 17510651904.0000\n",
      "Epoch 10/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17945733120.0000 - mse: 17945733120.0000 - val_loss: 17510287360.0000 - val_mse: 17510287360.0000\n",
      "Epoch 11/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17945362432.0000 - mse: 17945362432.0000 - val_loss: 17509922816.0000 - val_mse: 17509922816.0000\n",
      "Epoch 12/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17945006080.0000 - mse: 17945006080.0000 - val_loss: 17509574656.0000 - val_mse: 17509574656.0000\n",
      "Epoch 13/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17944647680.0000 - mse: 17944647680.0000 - val_loss: 17509199872.0000 - val_mse: 17509199872.0000\n",
      "Epoch 14/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17944283136.0000 - mse: 17944283136.0000 - val_loss: 17508845568.0000 - val_mse: 17508845568.0000\n",
      "Epoch 15/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17943924736.0000 - mse: 17943924736.0000 - val_loss: 17508489216.0000 - val_mse: 17508489216.0000\n",
      "Epoch 16/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17943541760.0000 - mse: 17943541760.0000 - val_loss: 17508128768.0000 - val_mse: 17508128768.0000\n",
      "Epoch 17/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17943183360.0000 - mse: 17943183360.0000 - val_loss: 17507782656.0000 - val_mse: 17507782656.0000\n",
      "Epoch 18/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17942827008.0000 - mse: 17942827008.0000 - val_loss: 17507411968.0000 - val_mse: 17507411968.0000\n",
      "Epoch 19/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17942458368.0000 - mse: 17942458368.0000 - val_loss: 17507047424.0000 - val_mse: 17507047424.0000\n",
      "Epoch 20/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17942110208.0000 - mse: 17942110208.0000 - val_loss: 17506703360.0000 - val_mse: 17506703360.0000\n",
      "Epoch 21/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17941743616.0000 - mse: 17941743616.0000 - val_loss: 17506322432.0000 - val_mse: 17506322432.0000\n",
      "Epoch 22/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17941368832.0000 - mse: 17941368832.0000 - val_loss: 17505976320.0000 - val_mse: 17505976320.0000\n",
      "Epoch 23/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17941012480.0000 - mse: 17941012480.0000 - val_loss: 17505613824.0000 - val_mse: 17505613824.0000\n",
      "Epoch 24/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17940643840.0000 - mse: 17940643840.0000 - val_loss: 17505259520.0000 - val_mse: 17505259520.0000\n",
      "Epoch 25/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17940291584.0000 - mse: 17940291584.0000 - val_loss: 17504905216.0000 - val_mse: 17504905216.0000\n",
      "Epoch 26/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17939933184.0000 - mse: 17939933184.0000 - val_loss: 17504532480.0000 - val_mse: 17504532480.0000\n",
      "Epoch 27/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17939558400.0000 - mse: 17939558400.0000 - val_loss: 17504169984.0000 - val_mse: 17504169984.0000\n",
      "Epoch 28/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17939200000.0000 - mse: 17939200000.0000 - val_loss: 17503821824.0000 - val_mse: 17503821824.0000\n",
      "Epoch 29/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17938851840.0000 - mse: 17938851840.0000 - val_loss: 17503442944.0000 - val_mse: 17503442944.0000\n",
      "Epoch 30/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17938472960.0000 - mse: 17938472960.0000 - val_loss: 17503109120.0000 - val_mse: 17503109120.0000\n",
      "Epoch 31/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17938122752.0000 - mse: 17938122752.0000 - val_loss: 17502740480.0000 - val_mse: 17502740480.0000\n",
      "Epoch 32/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17937762304.0000 - mse: 17937762304.0000 - val_loss: 17502371840.0000 - val_mse: 17502371840.0000\n",
      "Epoch 33/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17937401856.0000 - mse: 17937401856.0000 - val_loss: 17502035968.0000 - val_mse: 17502035968.0000\n",
      "Epoch 34/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17937008640.0000 - mse: 17937008640.0000 - val_loss: 17501669376.0000 - val_mse: 17501669376.0000\n",
      "Epoch 35/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17936678912.0000 - mse: 17936678912.0000 - val_loss: 17501290496.0000 - val_mse: 17501290496.0000\n",
      "Epoch 36/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17936283648.0000 - mse: 17936283648.0000 - val_loss: 17500940288.0000 - val_mse: 17500940288.0000\n",
      "Epoch 37/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17935953920.0000 - mse: 17935953920.0000 - val_loss: 17500592128.0000 - val_mse: 17500592128.0000\n",
      "Epoch 38/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17935579136.0000 - mse: 17935579136.0000 - val_loss: 17500221440.0000 - val_mse: 17500221440.0000\n",
      "Epoch 39/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17935206400.0000 - mse: 17935206400.0000 - val_loss: 17499871232.0000 - val_mse: 17499871232.0000\n",
      "Epoch 40/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17934841856.0000 - mse: 17934841856.0000 - val_loss: 17499510784.0000 - val_mse: 17499510784.0000\n",
      "Epoch 41/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17934489600.0000 - mse: 17934489600.0000 - val_loss: 17499140096.0000 - val_mse: 17499140096.0000\n",
      "Epoch 42/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17934120960.0000 - mse: 17934120960.0000 - val_loss: 17498789888.0000 - val_mse: 17498789888.0000\n",
      "Epoch 43/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17933776896.0000 - mse: 17933776896.0000 - val_loss: 17498427392.0000 - val_mse: 17498427392.0000\n",
      "Epoch 44/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17933383680.0000 - mse: 17933383680.0000 - val_loss: 17498060800.0000 - val_mse: 17498060800.0000\n",
      "Epoch 45/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17933039616.0000 - mse: 17933039616.0000 - val_loss: 17497708544.0000 - val_mse: 17497708544.0000\n",
      "Epoch 46/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17932681216.0000 - mse: 17932681216.0000 - val_loss: 17497352192.0000 - val_mse: 17497352192.0000\n",
      "Epoch 47/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17932294144.0000 - mse: 17932294144.0000 - val_loss: 17496985600.0000 - val_mse: 17496985600.0000\n",
      "Epoch 48/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17931937792.0000 - mse: 17931937792.0000 - val_loss: 17496639488.0000 - val_mse: 17496639488.0000\n",
      "Epoch 49/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17931579392.0000 - mse: 17931579392.0000 - val_loss: 17496272896.0000 - val_mse: 17496272896.0000\n",
      "Epoch 50/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17931216896.0000 - mse: 17931216896.0000 - val_loss: 17495908352.0000 - val_mse: 17495908352.0000\n",
      "Epoch 51/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17930876928.0000 - mse: 17930876928.0000 - val_loss: 17495556096.0000 - val_mse: 17495556096.0000\n",
      "Epoch 52/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17930518528.0000 - mse: 17930518528.0000 - val_loss: 17495193600.0000 - val_mse: 17495193600.0000\n",
      "Epoch 53/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17930147840.0000 - mse: 17930147840.0000 - val_loss: 17494831104.0000 - val_mse: 17494831104.0000\n",
      "Epoch 54/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17929783296.0000 - mse: 17929783296.0000 - val_loss: 17494474752.0000 - val_mse: 17494474752.0000\n",
      "Epoch 55/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17929396224.0000 - mse: 17929396224.0000 - val_loss: 17494120448.0000 - val_mse: 17494120448.0000\n",
      "Epoch 56/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17929050112.0000 - mse: 17929050112.0000 - val_loss: 17493743616.0000 - val_mse: 17493743616.0000\n",
      "Epoch 57/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17928691712.0000 - mse: 17928691712.0000 - val_loss: 17493391360.0000 - val_mse: 17493391360.0000\n",
      "Epoch 58/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17928308736.0000 - mse: 17928308736.0000 - val_loss: 17493045248.0000 - val_mse: 17493045248.0000\n",
      "Epoch 59/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17927964672.0000 - mse: 17927964672.0000 - val_loss: 17492688896.0000 - val_mse: 17492688896.0000\n",
      "Epoch 60/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17927596032.0000 - mse: 17927596032.0000 - val_loss: 17492318208.0000 - val_mse: 17492318208.0000\n",
      "Epoch 61/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17927239680.0000 - mse: 17927239680.0000 - val_loss: 17491963904.0000 - val_mse: 17491963904.0000\n",
      "Epoch 62/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17926868992.0000 - mse: 17926868992.0000 - val_loss: 17491603456.0000 - val_mse: 17491603456.0000\n",
      "Epoch 63/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17926492160.0000 - mse: 17926492160.0000 - val_loss: 17491240960.0000 - val_mse: 17491240960.0000\n",
      "Epoch 64/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17926141952.0000 - mse: 17926141952.0000 - val_loss: 17490886656.0000 - val_mse: 17490886656.0000\n",
      "Epoch 65/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17925773312.0000 - mse: 17925773312.0000 - val_loss: 17490520064.0000 - val_mse: 17490520064.0000\n",
      "Epoch 66/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17925396480.0000 - mse: 17925396480.0000 - val_loss: 17490169856.0000 - val_mse: 17490169856.0000\n",
      "Epoch 67/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17925033984.0000 - mse: 17925033984.0000 - val_loss: 17489803264.0000 - val_mse: 17489803264.0000\n",
      "Epoch 68/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17924698112.0000 - mse: 17924698112.0000 - val_loss: 17489451008.0000 - val_mse: 17489451008.0000\n",
      "Epoch 69/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17924319232.0000 - mse: 17924319232.0000 - val_loss: 17489094656.0000 - val_mse: 17489094656.0000\n",
      "Epoch 70/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17923962880.0000 - mse: 17923962880.0000 - val_loss: 17488711680.0000 - val_mse: 17488711680.0000\n",
      "Epoch 71/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17923618816.0000 - mse: 17923618816.0000 - val_loss: 17488381952.0000 - val_mse: 17488381952.0000\n",
      "Epoch 72/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17923244032.0000 - mse: 17923244032.0000 - val_loss: 17488003072.0000 - val_mse: 17488003072.0000\n",
      "Epoch 73/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17922867200.0000 - mse: 17922867200.0000 - val_loss: 17487646720.0000 - val_mse: 17487646720.0000\n",
      "Epoch 74/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17922527232.0000 - mse: 17922527232.0000 - val_loss: 17487306752.0000 - val_mse: 17487306752.0000\n",
      "Epoch 75/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17922187264.0000 - mse: 17922187264.0000 - val_loss: 17486929920.0000 - val_mse: 17486929920.0000\n",
      "Epoch 76/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17921794048.0000 - mse: 17921794048.0000 - val_loss: 17486579712.0000 - val_mse: 17486579712.0000\n",
      "Epoch 77/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17921433600.0000 - mse: 17921433600.0000 - val_loss: 17486206976.0000 - val_mse: 17486206976.0000\n",
      "Epoch 78/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17921077248.0000 - mse: 17921077248.0000 - val_loss: 17485858816.0000 - val_mse: 17485858816.0000\n",
      "Epoch 79/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17920702464.0000 - mse: 17920702464.0000 - val_loss: 17485500416.0000 - val_mse: 17485500416.0000\n",
      "Epoch 80/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17920348160.0000 - mse: 17920348160.0000 - val_loss: 17485127680.0000 - val_mse: 17485127680.0000\n",
      "Epoch 81/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17919979520.0000 - mse: 17919979520.0000 - val_loss: 17484785664.0000 - val_mse: 17484785664.0000\n",
      "Epoch 82/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17919623168.0000 - mse: 17919623168.0000 - val_loss: 17484423168.0000 - val_mse: 17484423168.0000\n",
      "Epoch 83/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17919258624.0000 - mse: 17919258624.0000 - val_loss: 17484048384.0000 - val_mse: 17484048384.0000\n",
      "Epoch 84/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17918912512.0000 - mse: 17918912512.0000 - val_loss: 17483706368.0000 - val_mse: 17483706368.0000\n",
      "Epoch 85/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17918523392.0000 - mse: 17918523392.0000 - val_loss: 17483352064.0000 - val_mse: 17483352064.0000\n",
      "Epoch 86/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17918152704.0000 - mse: 17918152704.0000 - val_loss: 17482985472.0000 - val_mse: 17482985472.0000\n",
      "Epoch 87/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17917798400.0000 - mse: 17917798400.0000 - val_loss: 17482616832.0000 - val_mse: 17482616832.0000\n",
      "Epoch 88/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17917440000.0000 - mse: 17917440000.0000 - val_loss: 17482272768.0000 - val_mse: 17482272768.0000\n",
      "Epoch 89/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17917093888.0000 - mse: 17917093888.0000 - val_loss: 17481912320.0000 - val_mse: 17481912320.0000\n",
      "Epoch 90/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17916717056.0000 - mse: 17916717056.0000 - val_loss: 17481525248.0000 - val_mse: 17481525248.0000\n",
      "Epoch 91/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17916348416.0000 - mse: 17916348416.0000 - val_loss: 17481187328.0000 - val_mse: 17481187328.0000\n",
      "Epoch 92/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17916000256.0000 - mse: 17916000256.0000 - val_loss: 17480824832.0000 - val_mse: 17480824832.0000\n",
      "Epoch 93/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17915643904.0000 - mse: 17915643904.0000 - val_loss: 17480470528.0000 - val_mse: 17480470528.0000\n",
      "Epoch 94/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17915258880.0000 - mse: 17915258880.0000 - val_loss: 17480114176.0000 - val_mse: 17480114176.0000\n",
      "Epoch 95/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17914898432.0000 - mse: 17914898432.0000 - val_loss: 17479761920.0000 - val_mse: 17479761920.0000\n",
      "Epoch 96/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17914540032.0000 - mse: 17914540032.0000 - val_loss: 17479391232.0000 - val_mse: 17479391232.0000\n",
      "Epoch 97/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17914173440.0000 - mse: 17914173440.0000 - val_loss: 17479036928.0000 - val_mse: 17479036928.0000\n",
      "Epoch 98/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17913808896.0000 - mse: 17913808896.0000 - val_loss: 17478670336.0000 - val_mse: 17478670336.0000\n",
      "Epoch 99/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17913448448.0000 - mse: 17913448448.0000 - val_loss: 17478322176.0000 - val_mse: 17478322176.0000\n",
      "Epoch 100/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17913104384.0000 - mse: 17913104384.0000 - val_loss: 17477961728.0000 - val_mse: 17477961728.0000\n",
      "Epoch 101/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17912723456.0000 - mse: 17912723456.0000 - val_loss: 17477595136.0000 - val_mse: 17477595136.0000\n",
      "Epoch 102/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17912381440.0000 - mse: 17912381440.0000 - val_loss: 17477244928.0000 - val_mse: 17477244928.0000\n",
      "Epoch 103/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17912006656.0000 - mse: 17912006656.0000 - val_loss: 17476882432.0000 - val_mse: 17476882432.0000\n",
      "Epoch 104/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17911642112.0000 - mse: 17911642112.0000 - val_loss: 17476526080.0000 - val_mse: 17476526080.0000\n",
      "Epoch 105/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17911267328.0000 - mse: 17911267328.0000 - val_loss: 17476163584.0000 - val_mse: 17476163584.0000\n",
      "Epoch 106/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17910915072.0000 - mse: 17910915072.0000 - val_loss: 17475809280.0000 - val_mse: 17475809280.0000\n",
      "Epoch 107/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17910556672.0000 - mse: 17910556672.0000 - val_loss: 17475442688.0000 - val_mse: 17475442688.0000\n",
      "Epoch 108/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17910198272.0000 - mse: 17910198272.0000 - val_loss: 17475082240.0000 - val_mse: 17475082240.0000\n",
      "Epoch 109/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17909819392.0000 - mse: 17909819392.0000 - val_loss: 17474725888.0000 - val_mse: 17474725888.0000\n",
      "Epoch 110/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17909465088.0000 - mse: 17909465088.0000 - val_loss: 17474373632.0000 - val_mse: 17474373632.0000\n",
      "Epoch 111/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17909098496.0000 - mse: 17909098496.0000 - val_loss: 17474017280.0000 - val_mse: 17474017280.0000\n",
      "Epoch 112/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17908750336.0000 - mse: 17908750336.0000 - val_loss: 17473648640.0000 - val_mse: 17473648640.0000\n",
      "Epoch 113/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17908385792.0000 - mse: 17908385792.0000 - val_loss: 17473290240.0000 - val_mse: 17473290240.0000\n",
      "Epoch 114/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17908013056.0000 - mse: 17908013056.0000 - val_loss: 17472933888.0000 - val_mse: 17472933888.0000\n",
      "Epoch 115/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17907658752.0000 - mse: 17907658752.0000 - val_loss: 17472565248.0000 - val_mse: 17472565248.0000\n",
      "Epoch 116/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17907302400.0000 - mse: 17907302400.0000 - val_loss: 17472215040.0000 - val_mse: 17472215040.0000\n",
      "Epoch 117/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17906941952.0000 - mse: 17906941952.0000 - val_loss: 17471866880.0000 - val_mse: 17471866880.0000\n",
      "Epoch 118/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17906583552.0000 - mse: 17906583552.0000 - val_loss: 17471500288.0000 - val_mse: 17471500288.0000\n",
      "Epoch 119/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17906202624.0000 - mse: 17906202624.0000 - val_loss: 17471131648.0000 - val_mse: 17471131648.0000\n",
      "Epoch 120/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17905846272.0000 - mse: 17905846272.0000 - val_loss: 17470791680.0000 - val_mse: 17470791680.0000\n",
      "Epoch 121/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17905479680.0000 - mse: 17905479680.0000 - val_loss: 17470418944.0000 - val_mse: 17470418944.0000\n",
      "Epoch 122/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17905133568.0000 - mse: 17905133568.0000 - val_loss: 17470052352.0000 - val_mse: 17470052352.0000\n",
      "Epoch 123/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17904766976.0000 - mse: 17904766976.0000 - val_loss: 17469706240.0000 - val_mse: 17469706240.0000\n",
      "Epoch 124/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17904388096.0000 - mse: 17904388096.0000 - val_loss: 17469351936.0000 - val_mse: 17469351936.0000\n",
      "Epoch 125/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17904019456.0000 - mse: 17904019456.0000 - val_loss: 17468989440.0000 - val_mse: 17468989440.0000\n",
      "Epoch 126/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17903659008.0000 - mse: 17903659008.0000 - val_loss: 17468624896.0000 - val_mse: 17468624896.0000\n",
      "Epoch 127/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17903327232.0000 - mse: 17903327232.0000 - val_loss: 17468286976.0000 - val_mse: 17468286976.0000\n",
      "Epoch 128/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17902958592.0000 - mse: 17902958592.0000 - val_loss: 17467901952.0000 - val_mse: 17467901952.0000\n",
      "Epoch 129/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17902596096.0000 - mse: 17902596096.0000 - val_loss: 17467559936.0000 - val_mse: 17467559936.0000\n",
      "Epoch 130/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17902247936.0000 - mse: 17902247936.0000 - val_loss: 17467199488.0000 - val_mse: 17467199488.0000\n",
      "Epoch 131/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17901852672.0000 - mse: 17901852672.0000 - val_loss: 17466832896.0000 - val_mse: 17466832896.0000\n",
      "Epoch 132/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17901508608.0000 - mse: 17901508608.0000 - val_loss: 17466484736.0000 - val_mse: 17466484736.0000\n",
      "Epoch 133/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17901144064.0000 - mse: 17901144064.0000 - val_loss: 17466114048.0000 - val_mse: 17466114048.0000\n",
      "Epoch 134/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17900775424.0000 - mse: 17900775424.0000 - val_loss: 17465755648.0000 - val_mse: 17465755648.0000\n",
      "Epoch 135/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17900439552.0000 - mse: 17900439552.0000 - val_loss: 17465405440.0000 - val_mse: 17465405440.0000\n",
      "Epoch 136/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17900058624.0000 - mse: 17900058624.0000 - val_loss: 17465038848.0000 - val_mse: 17465038848.0000\n",
      "Epoch 137/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17899669504.0000 - mse: 17899669504.0000 - val_loss: 17464688640.0000 - val_mse: 17464688640.0000\n",
      "Epoch 138/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17899329536.0000 - mse: 17899329536.0000 - val_loss: 17464324096.0000 - val_mse: 17464324096.0000\n",
      "Epoch 139/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17898956800.0000 - mse: 17898956800.0000 - val_loss: 17463969792.0000 - val_mse: 17463969792.0000\n",
      "Epoch 140/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17898627072.0000 - mse: 17898627072.0000 - val_loss: 17463605248.0000 - val_mse: 17463605248.0000\n",
      "Epoch 141/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17898231808.0000 - mse: 17898231808.0000 - val_loss: 17463248896.0000 - val_mse: 17463248896.0000\n",
      "Epoch 142/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17897881600.0000 - mse: 17897881600.0000 - val_loss: 17462888448.0000 - val_mse: 17462888448.0000\n",
      "Epoch 143/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17897510912.0000 - mse: 17897510912.0000 - val_loss: 17462523904.0000 - val_mse: 17462523904.0000\n",
      "Epoch 144/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17897170944.0000 - mse: 17897170944.0000 - val_loss: 17462171648.0000 - val_mse: 17462171648.0000\n",
      "Epoch 145/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17896808448.0000 - mse: 17896808448.0000 - val_loss: 17461813248.0000 - val_mse: 17461813248.0000\n",
      "Epoch 146/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17896443904.0000 - mse: 17896443904.0000 - val_loss: 17461460992.0000 - val_mse: 17461460992.0000\n",
      "Epoch 147/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17896054784.0000 - mse: 17896054784.0000 - val_loss: 17461094400.0000 - val_mse: 17461094400.0000\n",
      "Epoch 148/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17895712768.0000 - mse: 17895712768.0000 - val_loss: 17460736000.0000 - val_mse: 17460736000.0000\n",
      "Epoch 149/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17895356416.0000 - mse: 17895356416.0000 - val_loss: 17460383744.0000 - val_mse: 17460383744.0000\n",
      "Epoch 150/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17895002112.0000 - mse: 17895002112.0000 - val_loss: 17460015104.0000 - val_mse: 17460015104.0000\n",
      "Epoch 151/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17894627328.0000 - mse: 17894627328.0000 - val_loss: 17459666944.0000 - val_mse: 17459666944.0000\n",
      "Epoch 152/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17894277120.0000 - mse: 17894277120.0000 - val_loss: 17459304448.0000 - val_mse: 17459304448.0000\n",
      "Epoch 153/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17893902336.0000 - mse: 17893902336.0000 - val_loss: 17458939904.0000 - val_mse: 17458939904.0000\n",
      "Epoch 154/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17893523456.0000 - mse: 17893523456.0000 - val_loss: 17458593792.0000 - val_mse: 17458593792.0000\n",
      "Epoch 155/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17893165056.0000 - mse: 17893165056.0000 - val_loss: 17458225152.0000 - val_mse: 17458225152.0000\n",
      "Epoch 156/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17892825088.0000 - mse: 17892825088.0000 - val_loss: 17457858560.0000 - val_mse: 17457858560.0000\n",
      "Epoch 157/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17892452352.0000 - mse: 17892452352.0000 - val_loss: 17457516544.0000 - val_mse: 17457516544.0000\n",
      "Epoch 158/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17892112384.0000 - mse: 17892112384.0000 - val_loss: 17457141760.0000 - val_mse: 17457141760.0000\n",
      "Epoch 159/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17891756032.0000 - mse: 17891756032.0000 - val_loss: 17456793600.0000 - val_mse: 17456793600.0000\n",
      "Epoch 160/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17891366912.0000 - mse: 17891366912.0000 - val_loss: 17456427008.0000 - val_mse: 17456427008.0000\n",
      "Epoch 161/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17890988032.0000 - mse: 17890988032.0000 - val_loss: 17456068608.0000 - val_mse: 17456068608.0000\n",
      "Epoch 162/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17890648064.0000 - mse: 17890648064.0000 - val_loss: 17455732736.0000 - val_mse: 17455732736.0000\n",
      "Epoch 163/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17890299904.0000 - mse: 17890299904.0000 - val_loss: 17455351808.0000 - val_mse: 17455351808.0000\n",
      "Epoch 164/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17889900544.0000 - mse: 17889900544.0000 - val_loss: 17455003648.0000 - val_mse: 17455003648.0000\n",
      "Epoch 165/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17889550336.0000 - mse: 17889550336.0000 - val_loss: 17454657536.0000 - val_mse: 17454657536.0000\n",
      "Epoch 166/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17889208320.0000 - mse: 17889208320.0000 - val_loss: 17454282752.0000 - val_mse: 17454282752.0000\n",
      "Epoch 167/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17888831488.0000 - mse: 17888831488.0000 - val_loss: 17453924352.0000 - val_mse: 17453924352.0000\n",
      "Epoch 168/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17888479232.0000 - mse: 17888479232.0000 - val_loss: 17453574144.0000 - val_mse: 17453574144.0000\n",
      "Epoch 169/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17888100352.0000 - mse: 17888100352.0000 - val_loss: 17453205504.0000 - val_mse: 17453205504.0000\n",
      "Epoch 170/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17887748096.0000 - mse: 17887748096.0000 - val_loss: 17452855296.0000 - val_mse: 17452855296.0000\n",
      "Epoch 171/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17887391744.0000 - mse: 17887391744.0000 - val_loss: 17452496896.0000 - val_mse: 17452496896.0000\n",
      "Epoch 172/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17887029248.0000 - mse: 17887029248.0000 - val_loss: 17452120064.0000 - val_mse: 17452120064.0000\n",
      "Epoch 173/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17886672896.0000 - mse: 17886672896.0000 - val_loss: 17451784192.0000 - val_mse: 17451784192.0000\n",
      "Epoch 174/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17886285824.0000 - mse: 17886285824.0000 - val_loss: 17451413504.0000 - val_mse: 17451413504.0000\n",
      "Epoch 175/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17885949952.0000 - mse: 17885949952.0000 - val_loss: 17451055104.0000 - val_mse: 17451055104.0000\n",
      "Epoch 176/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17885579264.0000 - mse: 17885579264.0000 - val_loss: 17450706944.0000 - val_mse: 17450706944.0000\n",
      "Epoch 177/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17885218816.0000 - mse: 17885218816.0000 - val_loss: 17450334208.0000 - val_mse: 17450334208.0000\n",
      "Epoch 178/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17884835840.0000 - mse: 17884835840.0000 - val_loss: 17449981952.0000 - val_mse: 17449981952.0000\n",
      "Epoch 179/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17884485632.0000 - mse: 17884485632.0000 - val_loss: 17449633792.0000 - val_mse: 17449633792.0000\n",
      "Epoch 180/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17884125184.0000 - mse: 17884125184.0000 - val_loss: 17449267200.0000 - val_mse: 17449267200.0000\n",
      "Epoch 181/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17883770880.0000 - mse: 17883770880.0000 - val_loss: 17448904704.0000 - val_mse: 17448904704.0000\n",
      "Epoch 182/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17883414528.0000 - mse: 17883414528.0000 - val_loss: 17448552448.0000 - val_mse: 17448552448.0000\n",
      "Epoch 183/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17883049984.0000 - mse: 17883049984.0000 - val_loss: 17448196096.0000 - val_mse: 17448196096.0000\n",
      "Epoch 184/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17882685440.0000 - mse: 17882685440.0000 - val_loss: 17447833600.0000 - val_mse: 17447833600.0000\n",
      "Epoch 185/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17882320896.0000 - mse: 17882320896.0000 - val_loss: 17447487488.0000 - val_mse: 17447487488.0000\n",
      "Epoch 186/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17881964544.0000 - mse: 17881964544.0000 - val_loss: 17447106560.0000 - val_mse: 17447106560.0000\n",
      "Epoch 187/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17881606144.0000 - mse: 17881606144.0000 - val_loss: 17446762496.0000 - val_mse: 17446762496.0000\n",
      "Epoch 188/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17881233408.0000 - mse: 17881233408.0000 - val_loss: 17446410240.0000 - val_mse: 17446410240.0000\n",
      "Epoch 189/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17880875008.0000 - mse: 17880875008.0000 - val_loss: 17446027264.0000 - val_mse: 17446027264.0000\n",
      "Epoch 190/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17880520704.0000 - mse: 17880520704.0000 - val_loss: 17445695488.0000 - val_mse: 17445695488.0000\n",
      "Epoch 191/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17880145920.0000 - mse: 17880145920.0000 - val_loss: 17445330944.0000 - val_mse: 17445330944.0000\n",
      "Epoch 192/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17879785472.0000 - mse: 17879785472.0000 - val_loss: 17444945920.0000 - val_mse: 17444945920.0000\n",
      "Epoch 193/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17879433216.0000 - mse: 17879433216.0000 - val_loss: 17444616192.0000 - val_mse: 17444616192.0000\n",
      "Epoch 194/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17879058432.0000 - mse: 17879058432.0000 - val_loss: 17444261888.0000 - val_mse: 17444261888.0000\n",
      "Epoch 195/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17878712320.0000 - mse: 17878712320.0000 - val_loss: 17443876864.0000 - val_mse: 17443876864.0000\n",
      "Epoch 196/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17878345728.0000 - mse: 17878345728.0000 - val_loss: 17443540992.0000 - val_mse: 17443540992.0000\n",
      "Epoch 197/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17877970944.0000 - mse: 17877970944.0000 - val_loss: 17443182592.0000 - val_mse: 17443182592.0000\n",
      "Epoch 198/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17877618688.0000 - mse: 17877618688.0000 - val_loss: 17442799616.0000 - val_mse: 17442799616.0000\n",
      "Epoch 199/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17877245952.0000 - mse: 17877245952.0000 - val_loss: 17442461696.0000 - val_mse: 17442461696.0000\n",
      "Epoch 200/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17876891648.0000 - mse: 17876891648.0000 - val_loss: 17442111488.0000 - val_mse: 17442111488.0000\n",
      "Epoch 201/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17876520960.0000 - mse: 17876520960.0000 - val_loss: 17441738752.0000 - val_mse: 17441738752.0000\n",
      "Epoch 202/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17876172800.0000 - mse: 17876172800.0000 - val_loss: 17441392640.0000 - val_mse: 17441392640.0000\n",
      "Epoch 203/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17875812352.0000 - mse: 17875812352.0000 - val_loss: 17441021952.0000 - val_mse: 17441021952.0000\n",
      "Epoch 204/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17875462144.0000 - mse: 17875462144.0000 - val_loss: 17440667648.0000 - val_mse: 17440667648.0000\n",
      "Epoch 205/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17875101696.0000 - mse: 17875101696.0000 - val_loss: 17440323584.0000 - val_mse: 17440323584.0000\n",
      "Epoch 206/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17874722816.0000 - mse: 17874722816.0000 - val_loss: 17439940608.0000 - val_mse: 17439940608.0000\n",
      "Epoch 207/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17874360320.0000 - mse: 17874360320.0000 - val_loss: 17439596544.0000 - val_mse: 17439596544.0000\n",
      "Epoch 208/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17874006016.0000 - mse: 17874006016.0000 - val_loss: 17439246336.0000 - val_mse: 17439246336.0000\n",
      "Epoch 209/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17873637376.0000 - mse: 17873637376.0000 - val_loss: 17438871552.0000 - val_mse: 17438871552.0000\n",
      "Epoch 210/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17873266688.0000 - mse: 17873266688.0000 - val_loss: 17438513152.0000 - val_mse: 17438513152.0000\n",
      "Epoch 211/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17872912384.0000 - mse: 17872912384.0000 - val_loss: 17438164992.0000 - val_mse: 17438164992.0000\n",
      "Epoch 212/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17872558080.0000 - mse: 17872558080.0000 - val_loss: 17437814784.0000 - val_mse: 17437814784.0000\n",
      "Epoch 213/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17872189440.0000 - mse: 17872189440.0000 - val_loss: 17437450240.0000 - val_mse: 17437450240.0000\n",
      "Epoch 214/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17871839232.0000 - mse: 17871839232.0000 - val_loss: 17437100032.0000 - val_mse: 17437100032.0000\n",
      "Epoch 215/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17871478784.0000 - mse: 17871478784.0000 - val_loss: 17436725248.0000 - val_mse: 17436725248.0000\n",
      "Epoch 216/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17871108096.0000 - mse: 17871108096.0000 - val_loss: 17436348416.0000 - val_mse: 17436348416.0000\n",
      "Epoch 217/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17870768128.0000 - mse: 17870768128.0000 - val_loss: 17436018688.0000 - val_mse: 17436018688.0000\n",
      "Epoch 218/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17870399488.0000 - mse: 17870399488.0000 - val_loss: 17435662336.0000 - val_mse: 17435662336.0000\n",
      "Epoch 219/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17870036992.0000 - mse: 17870036992.0000 - val_loss: 17435293696.0000 - val_mse: 17435293696.0000\n",
      "Epoch 220/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17869660160.0000 - mse: 17869660160.0000 - val_loss: 17434943488.0000 - val_mse: 17434943488.0000\n",
      "Epoch 221/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17869305856.0000 - mse: 17869305856.0000 - val_loss: 17434574848.0000 - val_mse: 17434574848.0000\n",
      "Epoch 222/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17868941312.0000 - mse: 17868941312.0000 - val_loss: 17434222592.0000 - val_mse: 17434222592.0000\n",
      "Epoch 223/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17868554240.0000 - mse: 17868554240.0000 - val_loss: 17433872384.0000 - val_mse: 17433872384.0000\n",
      "Epoch 224/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17868222464.0000 - mse: 17868222464.0000 - val_loss: 17433497600.0000 - val_mse: 17433497600.0000\n",
      "Epoch 225/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17867859968.0000 - mse: 17867859968.0000 - val_loss: 17433151488.0000 - val_mse: 17433151488.0000\n",
      "Epoch 226/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17867495424.0000 - mse: 17867495424.0000 - val_loss: 17432803328.0000 - val_mse: 17432803328.0000\n",
      "Epoch 227/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17867137024.0000 - mse: 17867137024.0000 - val_loss: 17432428544.0000 - val_mse: 17432428544.0000\n",
      "Epoch 228/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17866780672.0000 - mse: 17866780672.0000 - val_loss: 17432074240.0000 - val_mse: 17432074240.0000\n",
      "Epoch 229/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17866414080.0000 - mse: 17866414080.0000 - val_loss: 17431726080.0000 - val_mse: 17431726080.0000\n",
      "Epoch 230/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17866043392.0000 - mse: 17866043392.0000 - val_loss: 17431359488.0000 - val_mse: 17431359488.0000\n",
      "Epoch 231/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17865699328.0000 - mse: 17865699328.0000 - val_loss: 17430999040.0000 - val_mse: 17430999040.0000\n",
      "Epoch 232/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17865324544.0000 - mse: 17865324544.0000 - val_loss: 17430646784.0000 - val_mse: 17430646784.0000\n",
      "Epoch 233/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17864974336.0000 - mse: 17864974336.0000 - val_loss: 17430290432.0000 - val_mse: 17430290432.0000\n",
      "Epoch 234/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17864609792.0000 - mse: 17864609792.0000 - val_loss: 17429923840.0000 - val_mse: 17429923840.0000\n",
      "Epoch 235/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17864247296.0000 - mse: 17864247296.0000 - val_loss: 17429569536.0000 - val_mse: 17429569536.0000\n",
      "Epoch 236/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17863866368.0000 - mse: 17863866368.0000 - val_loss: 17429229568.0000 - val_mse: 17429229568.0000\n",
      "Epoch 237/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17863499776.0000 - mse: 17863499776.0000 - val_loss: 17428830208.0000 - val_mse: 17428830208.0000\n",
      "Epoch 238/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17863161856.0000 - mse: 17863161856.0000 - val_loss: 17428490240.0000 - val_mse: 17428490240.0000\n",
      "Epoch 239/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17862799360.0000 - mse: 17862799360.0000 - val_loss: 17428148224.0000 - val_mse: 17428148224.0000\n",
      "Epoch 240/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17862461440.0000 - mse: 17862461440.0000 - val_loss: 17427777536.0000 - val_mse: 17427777536.0000\n",
      "Epoch 241/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17862074368.0000 - mse: 17862074368.0000 - val_loss: 17427427328.0000 - val_mse: 17427427328.0000\n",
      "Epoch 242/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17861711872.0000 - mse: 17861711872.0000 - val_loss: 17427066880.0000 - val_mse: 17427066880.0000\n",
      "Epoch 243/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17861349376.0000 - mse: 17861349376.0000 - val_loss: 17426702336.0000 - val_mse: 17426702336.0000\n",
      "Epoch 244/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17860986880.0000 - mse: 17860986880.0000 - val_loss: 17426329600.0000 - val_mse: 17426329600.0000\n",
      "Epoch 245/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17860622336.0000 - mse: 17860622336.0000 - val_loss: 17425995776.0000 - val_mse: 17425995776.0000\n",
      "Epoch 246/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17860276224.0000 - mse: 17860276224.0000 - val_loss: 17425639424.0000 - val_mse: 17425639424.0000\n",
      "Epoch 247/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17859901440.0000 - mse: 17859901440.0000 - val_loss: 17425281024.0000 - val_mse: 17425281024.0000\n",
      "Epoch 248/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17859547136.0000 - mse: 17859547136.0000 - val_loss: 17424916480.0000 - val_mse: 17424916480.0000\n",
      "Epoch 249/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17859168256.0000 - mse: 17859168256.0000 - val_loss: 17424556032.0000 - val_mse: 17424556032.0000\n",
      "Epoch 250/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17858830336.0000 - mse: 17858830336.0000 - val_loss: 17424216064.0000 - val_mse: 17424216064.0000\n",
      "Epoch 251/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17858465792.0000 - mse: 17858465792.0000 - val_loss: 17423843328.0000 - val_mse: 17423843328.0000\n",
      "Epoch 252/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17858107392.0000 - mse: 17858107392.0000 - val_loss: 17423476736.0000 - val_mse: 17423476736.0000\n",
      "Epoch 253/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17857748992.0000 - mse: 17857748992.0000 - val_loss: 17423134720.0000 - val_mse: 17423134720.0000\n",
      "Epoch 254/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17857363968.0000 - mse: 17857363968.0000 - val_loss: 17422774272.0000 - val_mse: 17422774272.0000\n",
      "Epoch 255/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17857038336.0000 - mse: 17857038336.0000 - val_loss: 17422403584.0000 - val_mse: 17422403584.0000\n",
      "Epoch 256/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17856655360.0000 - mse: 17856655360.0000 - val_loss: 17422059520.0000 - val_mse: 17422059520.0000\n",
      "Epoch 257/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17856301056.0000 - mse: 17856301056.0000 - val_loss: 17421707264.0000 - val_mse: 17421707264.0000\n",
      "Epoch 258/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17855936512.0000 - mse: 17855936512.0000 - val_loss: 17421336576.0000 - val_mse: 17421336576.0000\n",
      "Epoch 259/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17855586304.0000 - mse: 17855586304.0000 - val_loss: 17420967936.0000 - val_mse: 17420967936.0000\n",
      "Epoch 260/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17855209472.0000 - mse: 17855209472.0000 - val_loss: 17420632064.0000 - val_mse: 17420632064.0000\n",
      "Epoch 261/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17854859264.0000 - mse: 17854859264.0000 - val_loss: 17420257280.0000 - val_mse: 17420257280.0000\n",
      "Epoch 262/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17854476288.0000 - mse: 17854476288.0000 - val_loss: 17419902976.0000 - val_mse: 17419902976.0000\n",
      "Epoch 263/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17854142464.0000 - mse: 17854142464.0000 - val_loss: 17419552768.0000 - val_mse: 17419552768.0000\n",
      "Epoch 264/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17853777920.0000 - mse: 17853777920.0000 - val_loss: 17419202560.0000 - val_mse: 17419202560.0000\n",
      "Epoch 265/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17853405184.0000 - mse: 17853405184.0000 - val_loss: 17418825728.0000 - val_mse: 17418825728.0000\n",
      "Epoch 266/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17853054976.0000 - mse: 17853054976.0000 - val_loss: 17418489856.0000 - val_mse: 17418489856.0000\n",
      "Epoch 267/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17852676096.0000 - mse: 17852676096.0000 - val_loss: 17418119168.0000 - val_mse: 17418119168.0000\n",
      "Epoch 268/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17852317696.0000 - mse: 17852317696.0000 - val_loss: 17417750528.0000 - val_mse: 17417750528.0000\n",
      "Epoch 269/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17851957248.0000 - mse: 17851957248.0000 - val_loss: 17417414656.0000 - val_mse: 17417414656.0000\n",
      "Epoch 270/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17851604992.0000 - mse: 17851604992.0000 - val_loss: 17417043968.0000 - val_mse: 17417043968.0000\n",
      "Epoch 271/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17851226112.0000 - mse: 17851226112.0000 - val_loss: 17416683520.0000 - val_mse: 17416683520.0000\n",
      "Epoch 272/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17850857472.0000 - mse: 17850857472.0000 - val_loss: 17416345600.0000 - val_mse: 17416345600.0000\n",
      "Epoch 273/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17850517504.0000 - mse: 17850517504.0000 - val_loss: 17415958528.0000 - val_mse: 17415958528.0000\n",
      "Epoch 274/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17850155008.0000 - mse: 17850155008.0000 - val_loss: 17415610368.0000 - val_mse: 17415610368.0000\n",
      "Epoch 275/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17849782272.0000 - mse: 17849782272.0000 - val_loss: 17415264256.0000 - val_mse: 17415264256.0000\n",
      "Epoch 276/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17849413632.0000 - mse: 17849413632.0000 - val_loss: 17414887424.0000 - val_mse: 17414887424.0000\n",
      "Epoch 277/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17849073664.0000 - mse: 17849073664.0000 - val_loss: 17414545408.0000 - val_mse: 17414545408.0000\n",
      "Epoch 278/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17848713216.0000 - mse: 17848713216.0000 - val_loss: 17414199296.0000 - val_mse: 17414199296.0000\n",
      "Epoch 279/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17848360960.0000 - mse: 17848360960.0000 - val_loss: 17413826560.0000 - val_mse: 17413826560.0000\n",
      "Epoch 280/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17847975936.0000 - mse: 17847975936.0000 - val_loss: 17413472256.0000 - val_mse: 17413472256.0000\n",
      "Epoch 281/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17847629824.0000 - mse: 17847629824.0000 - val_loss: 17413111808.0000 - val_mse: 17413111808.0000\n",
      "Epoch 282/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17847255040.0000 - mse: 17847255040.0000 - val_loss: 17412749312.0000 - val_mse: 17412749312.0000\n",
      "Epoch 283/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17846890496.0000 - mse: 17846890496.0000 - val_loss: 17412405248.0000 - val_mse: 17412405248.0000\n",
      "Epoch 284/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17846525952.0000 - mse: 17846525952.0000 - val_loss: 17412032512.0000 - val_mse: 17412032512.0000\n",
      "Epoch 285/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17846198272.0000 - mse: 17846198272.0000 - val_loss: 17411678208.0000 - val_mse: 17411678208.0000\n",
      "Epoch 286/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17845827584.0000 - mse: 17845827584.0000 - val_loss: 17411328000.0000 - val_mse: 17411328000.0000\n",
      "Epoch 287/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17845465088.0000 - mse: 17845465088.0000 - val_loss: 17410965504.0000 - val_mse: 17410965504.0000\n",
      "Epoch 288/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17845094400.0000 - mse: 17845094400.0000 - val_loss: 17410605056.0000 - val_mse: 17410605056.0000\n",
      "Epoch 289/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17844733952.0000 - mse: 17844733952.0000 - val_loss: 17410258944.0000 - val_mse: 17410258944.0000\n",
      "Epoch 290/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17844377600.0000 - mse: 17844377600.0000 - val_loss: 17409890304.0000 - val_mse: 17409890304.0000\n",
      "Epoch 291/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17844023296.0000 - mse: 17844023296.0000 - val_loss: 17409521664.0000 - val_mse: 17409521664.0000\n",
      "Epoch 292/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17843648512.0000 - mse: 17843648512.0000 - val_loss: 17409181696.0000 - val_mse: 17409181696.0000\n",
      "Epoch 293/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17843286016.0000 - mse: 17843286016.0000 - val_loss: 17408829440.0000 - val_mse: 17408829440.0000\n",
      "Epoch 294/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17842937856.0000 - mse: 17842937856.0000 - val_loss: 17408456704.0000 - val_mse: 17408456704.0000\n",
      "Epoch 295/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17842565120.0000 - mse: 17842565120.0000 - val_loss: 17408104448.0000 - val_mse: 17408104448.0000\n",
      "Epoch 296/600\n",
      "1872/1872 [==============================] - 7s 3ms/step - loss: 17842208768.0000 - mse: 17842208768.0000 - val_loss: 17407750144.0000 - val_mse: 17407750144.0000\n",
      "Epoch 297/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17841860608.0000 - mse: 17841860608.0000 - val_loss: 17407389696.0000 - val_mse: 17407389696.0000\n",
      "Epoch 298/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17841483776.0000 - mse: 17841483776.0000 - val_loss: 17407037440.0000 - val_mse: 17407037440.0000\n",
      "Epoch 299/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17841119232.0000 - mse: 17841119232.0000 - val_loss: 17406695424.0000 - val_mse: 17406695424.0000\n",
      "Epoch 300/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17840775168.0000 - mse: 17840775168.0000 - val_loss: 17406308352.0000 - val_mse: 17406308352.0000\n",
      "Epoch 301/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17840414720.0000 - mse: 17840414720.0000 - val_loss: 17405968384.0000 - val_mse: 17405968384.0000\n",
      "Epoch 302/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17840035840.0000 - mse: 17840035840.0000 - val_loss: 17405593600.0000 - val_mse: 17405593600.0000\n",
      "Epoch 303/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17839687680.0000 - mse: 17839687680.0000 - val_loss: 17405239296.0000 - val_mse: 17405239296.0000\n",
      "Epoch 304/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17839323136.0000 - mse: 17839323136.0000 - val_loss: 17404895232.0000 - val_mse: 17404895232.0000\n",
      "Epoch 305/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17838968832.0000 - mse: 17838968832.0000 - val_loss: 17404528640.0000 - val_mse: 17404528640.0000\n",
      "Epoch 306/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17838600192.0000 - mse: 17838600192.0000 - val_loss: 17404176384.0000 - val_mse: 17404176384.0000\n",
      "Epoch 307/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17838221312.0000 - mse: 17838221312.0000 - val_loss: 17403811840.0000 - val_mse: 17403811840.0000\n",
      "Epoch 308/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17837869056.0000 - mse: 17837869056.0000 - val_loss: 17403455488.0000 - val_mse: 17403455488.0000\n",
      "Epoch 309/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17837524992.0000 - mse: 17837524992.0000 - val_loss: 17403107328.0000 - val_mse: 17403107328.0000\n",
      "Epoch 310/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17837154304.0000 - mse: 17837154304.0000 - val_loss: 17402738688.0000 - val_mse: 17402738688.0000\n",
      "Epoch 311/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17836795904.0000 - mse: 17836795904.0000 - val_loss: 17402390528.0000 - val_mse: 17402390528.0000\n",
      "Epoch 312/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17836435456.0000 - mse: 17836435456.0000 - val_loss: 17402023936.0000 - val_mse: 17402023936.0000\n",
      "Epoch 313/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17836072960.0000 - mse: 17836072960.0000 - val_loss: 17401671680.0000 - val_mse: 17401671680.0000\n",
      "Epoch 314/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17835718656.0000 - mse: 17835718656.0000 - val_loss: 17401315328.0000 - val_mse: 17401315328.0000\n",
      "Epoch 315/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17835368448.0000 - mse: 17835368448.0000 - val_loss: 17400956928.0000 - val_mse: 17400956928.0000\n",
      "Epoch 316/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17834993664.0000 - mse: 17834993664.0000 - val_loss: 17400598528.0000 - val_mse: 17400598528.0000\n",
      "Epoch 317/600\n",
      "1872/1872 [==============================] - 9s 5ms/step - loss: 17834657792.0000 - mse: 17834657792.0000 - val_loss: 17400236032.0000 - val_mse: 17400236032.0000\n",
      "Epoch 318/600\n",
      "1872/1872 [==============================] - 10s 5ms/step - loss: 17834272768.0000 - mse: 17834272768.0000 - val_loss: 17399894016.0000 - val_mse: 17399894016.0000\n",
      "Epoch 319/600\n",
      "1872/1872 [==============================] - 10s 5ms/step - loss: 17833916416.0000 - mse: 17833916416.0000 - val_loss: 17399511040.0000 - val_mse: 17399511040.0000\n",
      "Epoch 320/600\n",
      "1872/1872 [==============================] - 10s 5ms/step - loss: 17833566208.0000 - mse: 17833566208.0000 - val_loss: 17399177216.0000 - val_mse: 17399177216.0000\n",
      "Epoch 321/600\n",
      "1872/1872 [==============================] - 9s 5ms/step - loss: 17833187328.0000 - mse: 17833187328.0000 - val_loss: 17398816768.0000 - val_mse: 17398816768.0000\n",
      "Epoch 322/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17832824832.0000 - mse: 17832824832.0000 - val_loss: 17398450176.0000 - val_mse: 17398450176.0000\n",
      "Epoch 323/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 10s 5ms/step - loss: 17832466432.0000 - mse: 17832466432.0000 - val_loss: 17398106112.0000 - val_mse: 17398106112.0000\n",
      "Epoch 324/600\n",
      "1872/1872 [==============================] - 11s 6ms/step - loss: 17832114176.0000 - mse: 17832114176.0000 - val_loss: 17397739520.0000 - val_mse: 17397739520.0000\n",
      "Epoch 325/600\n",
      "1872/1872 [==============================] - 11s 6ms/step - loss: 17831741440.0000 - mse: 17831741440.0000 - val_loss: 17397381120.0000 - val_mse: 17397381120.0000\n",
      "Epoch 326/600\n",
      "1872/1872 [==============================] - 11s 6ms/step - loss: 17831378944.0000 - mse: 17831378944.0000 - val_loss: 17397043200.0000 - val_mse: 17397043200.0000\n",
      "Epoch 327/600\n",
      "1872/1872 [==============================] - 9s 5ms/step - loss: 17831020544.0000 - mse: 17831020544.0000 - val_loss: 17396664320.0000 - val_mse: 17396664320.0000\n",
      "Epoch 328/600\n",
      "1872/1872 [==============================] - 9s 5ms/step - loss: 17830658048.0000 - mse: 17830658048.0000 - val_loss: 17396305920.0000 - val_mse: 17396305920.0000\n",
      "Epoch 329/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17830309888.0000 - mse: 17830309888.0000 - val_loss: 17395972096.0000 - val_mse: 17395972096.0000\n",
      "Epoch 330/600\n",
      "1872/1872 [==============================] - 9s 5ms/step - loss: 17829957632.0000 - mse: 17829957632.0000 - val_loss: 17395585024.0000 - val_mse: 17395585024.0000\n",
      "Epoch 331/600\n",
      "1872/1872 [==============================] - 9s 5ms/step - loss: 17829580800.0000 - mse: 17829580800.0000 - val_loss: 17395243008.0000 - val_mse: 17395243008.0000\n",
      "Epoch 332/600\n",
      "1872/1872 [==============================] - 10s 5ms/step - loss: 17829214208.0000 - mse: 17829214208.0000 - val_loss: 17394896896.0000 - val_mse: 17394896896.0000\n",
      "Epoch 333/600\n",
      "1872/1872 [==============================] - 9s 5ms/step - loss: 17828855808.0000 - mse: 17828855808.0000 - val_loss: 17394509824.0000 - val_mse: 17394509824.0000\n",
      "Epoch 334/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17828487168.0000 - mse: 17828487168.0000 - val_loss: 17394167808.0000 - val_mse: 17394167808.0000\n",
      "Epoch 335/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17828128768.0000 - mse: 17828128768.0000 - val_loss: 17393809408.0000 - val_mse: 17393809408.0000\n",
      "Epoch 336/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17827786752.0000 - mse: 17827786752.0000 - val_loss: 17393446912.0000 - val_mse: 17393446912.0000\n",
      "Epoch 337/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17827409920.0000 - mse: 17827409920.0000 - val_loss: 17393086464.0000 - val_mse: 17393086464.0000\n",
      "Epoch 338/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17827088384.0000 - mse: 17827088384.0000 - val_loss: 17392748544.0000 - val_mse: 17392748544.0000\n",
      "Epoch 339/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17826678784.0000 - mse: 17826678784.0000 - val_loss: 17392379904.0000 - val_mse: 17392379904.0000\n",
      "Epoch 340/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17826336768.0000 - mse: 17826336768.0000 - val_loss: 17392025600.0000 - val_mse: 17392025600.0000\n",
      "Epoch 341/600\n",
      "1872/1872 [==============================] - 8s 5ms/step - loss: 17825982464.0000 - mse: 17825982464.0000 - val_loss: 17391669248.0000 - val_mse: 17391669248.0000\n",
      "Epoch 342/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17825630208.0000 - mse: 17825630208.0000 - val_loss: 17391300608.0000 - val_mse: 17391300608.0000\n",
      "Epoch 343/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17825236992.0000 - mse: 17825236992.0000 - val_loss: 17390942208.0000 - val_mse: 17390942208.0000\n",
      "Epoch 344/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17824899072.0000 - mse: 17824899072.0000 - val_loss: 17390602240.0000 - val_mse: 17390602240.0000\n",
      "Epoch 345/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17824536576.0000 - mse: 17824536576.0000 - val_loss: 17390231552.0000 - val_mse: 17390231552.0000\n",
      "Epoch 346/600\n",
      "1872/1872 [==============================] - 8s 5ms/step - loss: 17824176128.0000 - mse: 17824176128.0000 - val_loss: 17389879296.0000 - val_mse: 17389879296.0000\n",
      "Epoch 347/600\n",
      "1872/1872 [==============================] - 9s 5ms/step - loss: 17823825920.0000 - mse: 17823825920.0000 - val_loss: 17389529088.0000 - val_mse: 17389529088.0000\n",
      "Epoch 348/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17823449088.0000 - mse: 17823449088.0000 - val_loss: 17389158400.0000 - val_mse: 17389158400.0000\n",
      "Epoch 349/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17823076352.0000 - mse: 17823076352.0000 - val_loss: 17388818432.0000 - val_mse: 17388818432.0000\n",
      "Epoch 350/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17822734336.0000 - mse: 17822734336.0000 - val_loss: 17388457984.0000 - val_mse: 17388457984.0000\n",
      "Epoch 351/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17822369792.0000 - mse: 17822369792.0000 - val_loss: 17388079104.0000 - val_mse: 17388079104.0000\n",
      "Epoch 352/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17822009344.0000 - mse: 17822009344.0000 - val_loss: 17387749376.0000 - val_mse: 17387749376.0000\n",
      "Epoch 353/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17821626368.0000 - mse: 17821626368.0000 - val_loss: 17387384832.0000 - val_mse: 17387384832.0000\n",
      "Epoch 354/600\n",
      "1872/1872 [==============================] - 7s 3ms/step - loss: 17821290496.0000 - mse: 17821290496.0000 - val_loss: 17387022336.0000 - val_mse: 17387022336.0000\n",
      "Epoch 355/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17820936192.0000 - mse: 17820936192.0000 - val_loss: 17386659840.0000 - val_mse: 17386659840.0000\n",
      "Epoch 356/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17820553216.0000 - mse: 17820553216.0000 - val_loss: 17386305536.0000 - val_mse: 17386305536.0000\n",
      "Epoch 357/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17820213248.0000 - mse: 17820213248.0000 - val_loss: 17385957376.0000 - val_mse: 17385957376.0000\n",
      "Epoch 358/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17819815936.0000 - mse: 17819815936.0000 - val_loss: 17385592832.0000 - val_mse: 17385592832.0000\n",
      "Epoch 359/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17819490304.0000 - mse: 17819490304.0000 - val_loss: 17385238528.0000 - val_mse: 17385238528.0000\n",
      "Epoch 360/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17819136000.0000 - mse: 17819136000.0000 - val_loss: 17384884224.0000 - val_mse: 17384884224.0000\n",
      "Epoch 361/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17818750976.0000 - mse: 17818750976.0000 - val_loss: 17384519680.0000 - val_mse: 17384519680.0000\n",
      "Epoch 362/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17818394624.0000 - mse: 17818394624.0000 - val_loss: 17384167424.0000 - val_mse: 17384167424.0000\n",
      "Epoch 363/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17818060800.0000 - mse: 17818060800.0000 - val_loss: 17383817216.0000 - val_mse: 17383817216.0000\n",
      "Epoch 364/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17817669632.0000 - mse: 17817669632.0000 - val_loss: 17383450624.0000 - val_mse: 17383450624.0000\n",
      "Epoch 365/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17817313280.0000 - mse: 17817313280.0000 - val_loss: 17383102464.0000 - val_mse: 17383102464.0000\n",
      "Epoch 366/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17816961024.0000 - mse: 17816961024.0000 - val_loss: 17382742016.0000 - val_mse: 17382742016.0000\n",
      "Epoch 367/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17816610816.0000 - mse: 17816610816.0000 - val_loss: 17382375424.0000 - val_mse: 17382375424.0000\n",
      "Epoch 368/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17816240128.0000 - mse: 17816240128.0000 - val_loss: 17382029312.0000 - val_mse: 17382029312.0000\n",
      "Epoch 369/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17815869440.0000 - mse: 17815869440.0000 - val_loss: 17381664768.0000 - val_mse: 17381664768.0000\n",
      "Epoch 370/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17815521280.0000 - mse: 17815521280.0000 - val_loss: 17381296128.0000 - val_mse: 17381296128.0000\n",
      "Epoch 371/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17815169024.0000 - mse: 17815169024.0000 - val_loss: 17380956160.0000 - val_mse: 17380956160.0000\n",
      "Epoch 372/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17814804480.0000 - mse: 17814804480.0000 - val_loss: 17380605952.0000 - val_mse: 17380605952.0000\n",
      "Epoch 373/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17814423552.0000 - mse: 17814423552.0000 - val_loss: 17380218880.0000 - val_mse: 17380218880.0000\n",
      "Epoch 374/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17814083584.0000 - mse: 17814083584.0000 - val_loss: 17379887104.0000 - val_mse: 17379887104.0000\n",
      "Epoch 375/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17813696512.0000 - mse: 17813696512.0000 - val_loss: 17379526656.0000 - val_mse: 17379526656.0000\n",
      "Epoch 376/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17813352448.0000 - mse: 17813352448.0000 - val_loss: 17379158016.0000 - val_mse: 17379158016.0000\n",
      "Epoch 377/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17812983808.0000 - mse: 17812983808.0000 - val_loss: 17378805760.0000 - val_mse: 17378805760.0000\n",
      "Epoch 378/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17812633600.0000 - mse: 17812633600.0000 - val_loss: 17378465792.0000 - val_mse: 17378465792.0000\n",
      "Epoch 379/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17812256768.0000 - mse: 17812256768.0000 - val_loss: 17378088960.0000 - val_mse: 17378088960.0000\n",
      "Epoch 380/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17811912704.0000 - mse: 17811912704.0000 - val_loss: 17377732608.0000 - val_mse: 17377732608.0000\n",
      "Epoch 381/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17811572736.0000 - mse: 17811572736.0000 - val_loss: 17377394688.0000 - val_mse: 17377394688.0000\n",
      "Epoch 382/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17811187712.0000 - mse: 17811187712.0000 - val_loss: 17377015808.0000 - val_mse: 17377015808.0000\n",
      "Epoch 383/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17810837504.0000 - mse: 17810837504.0000 - val_loss: 17376665600.0000 - val_mse: 17376665600.0000\n",
      "Epoch 384/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17810456576.0000 - mse: 17810456576.0000 - val_loss: 17376311296.0000 - val_mse: 17376311296.0000\n",
      "Epoch 385/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17810104320.0000 - mse: 17810104320.0000 - val_loss: 17375954944.0000 - val_mse: 17375954944.0000\n",
      "Epoch 386/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17809754112.0000 - mse: 17809754112.0000 - val_loss: 17375604736.0000 - val_mse: 17375604736.0000\n",
      "Epoch 387/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17809379328.0000 - mse: 17809379328.0000 - val_loss: 17375242240.0000 - val_mse: 17375242240.0000\n",
      "Epoch 388/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17809022976.0000 - mse: 17809022976.0000 - val_loss: 17374885888.0000 - val_mse: 17374885888.0000\n",
      "Epoch 389/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17808674816.0000 - mse: 17808674816.0000 - val_loss: 17374525440.0000 - val_mse: 17374525440.0000\n",
      "Epoch 390/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17808306176.0000 - mse: 17808306176.0000 - val_loss: 17374160896.0000 - val_mse: 17374160896.0000\n",
      "Epoch 391/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17807960064.0000 - mse: 17807960064.0000 - val_loss: 17373820928.0000 - val_mse: 17373820928.0000\n",
      "Epoch 392/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17807577088.0000 - mse: 17807577088.0000 - val_loss: 17373460480.0000 - val_mse: 17373460480.0000\n",
      "Epoch 393/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17807235072.0000 - mse: 17807235072.0000 - val_loss: 17373085696.0000 - val_mse: 17373085696.0000\n",
      "Epoch 394/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17806858240.0000 - mse: 17806858240.0000 - val_loss: 17372749824.0000 - val_mse: 17372749824.0000\n",
      "Epoch 395/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17806497792.0000 - mse: 17806497792.0000 - val_loss: 17372387328.0000 - val_mse: 17372387328.0000\n",
      "Epoch 396/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17806157824.0000 - mse: 17806157824.0000 - val_loss: 17372024832.0000 - val_mse: 17372024832.0000\n",
      "Epoch 397/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17805778944.0000 - mse: 17805778944.0000 - val_loss: 17371670528.0000 - val_mse: 17371670528.0000\n",
      "Epoch 398/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17805434880.0000 - mse: 17805434880.0000 - val_loss: 17371312128.0000 - val_mse: 17371312128.0000\n",
      "Epoch 399/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17805060096.0000 - mse: 17805060096.0000 - val_loss: 17370972160.0000 - val_mse: 17370972160.0000\n",
      "Epoch 400/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17804697600.0000 - mse: 17804697600.0000 - val_loss: 17370603520.0000 - val_mse: 17370603520.0000\n",
      "Epoch 401/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17804355584.0000 - mse: 17804355584.0000 - val_loss: 17370257408.0000 - val_mse: 17370257408.0000\n",
      "Epoch 402/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17803978752.0000 - mse: 17803978752.0000 - val_loss: 17369886720.0000 - val_mse: 17369886720.0000\n",
      "Epoch 403/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17803618304.0000 - mse: 17803618304.0000 - val_loss: 17369534464.0000 - val_mse: 17369534464.0000\n",
      "Epoch 404/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17803249664.0000 - mse: 17803249664.0000 - val_loss: 17369176064.0000 - val_mse: 17369176064.0000\n",
      "Epoch 405/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17802911744.0000 - mse: 17802911744.0000 - val_loss: 17368811520.0000 - val_mse: 17368811520.0000\n",
      "Epoch 406/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17802547200.0000 - mse: 17802547200.0000 - val_loss: 17368477696.0000 - val_mse: 17368477696.0000\n",
      "Epoch 407/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17802174464.0000 - mse: 17802174464.0000 - val_loss: 17368100864.0000 - val_mse: 17368100864.0000\n",
      "Epoch 408/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17801824256.0000 - mse: 17801824256.0000 - val_loss: 17367736320.0000 - val_mse: 17367736320.0000\n",
      "Epoch 409/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17801451520.0000 - mse: 17801451520.0000 - val_loss: 17367394304.0000 - val_mse: 17367394304.0000\n",
      "Epoch 410/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17801093120.0000 - mse: 17801093120.0000 - val_loss: 17367037952.0000 - val_mse: 17367037952.0000\n",
      "Epoch 411/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17800753152.0000 - mse: 17800753152.0000 - val_loss: 17366681600.0000 - val_mse: 17366681600.0000\n",
      "Epoch 412/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17800374272.0000 - mse: 17800374272.0000 - val_loss: 17366321152.0000 - val_mse: 17366321152.0000\n",
      "Epoch 413/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17800034304.0000 - mse: 17800034304.0000 - val_loss: 17365970944.0000 - val_mse: 17365970944.0000\n",
      "Epoch 414/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17799649280.0000 - mse: 17799649280.0000 - val_loss: 17365606400.0000 - val_mse: 17365606400.0000\n",
      "Epoch 415/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17799303168.0000 - mse: 17799303168.0000 - val_loss: 17365258240.0000 - val_mse: 17365258240.0000\n",
      "Epoch 416/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17798940672.0000 - mse: 17798940672.0000 - val_loss: 17364905984.0000 - val_mse: 17364905984.0000\n",
      "Epoch 417/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17798596608.0000 - mse: 17798596608.0000 - val_loss: 17364537344.0000 - val_mse: 17364537344.0000\n",
      "Epoch 418/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17798203392.0000 - mse: 17798203392.0000 - val_loss: 17364185088.0000 - val_mse: 17364185088.0000\n",
      "Epoch 419/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17797867520.0000 - mse: 17797867520.0000 - val_loss: 17363836928.0000 - val_mse: 17363836928.0000\n",
      "Epoch 420/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17797513216.0000 - mse: 17797513216.0000 - val_loss: 17363462144.0000 - val_mse: 17363462144.0000\n",
      "Epoch 421/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17797144576.0000 - mse: 17797144576.0000 - val_loss: 17363116032.0000 - val_mse: 17363116032.0000\n",
      "Epoch 422/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17796794368.0000 - mse: 17796794368.0000 - val_loss: 17362763776.0000 - val_mse: 17362763776.0000\n",
      "Epoch 423/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17796421632.0000 - mse: 17796421632.0000 - val_loss: 17362397184.0000 - val_mse: 17362397184.0000\n",
      "Epoch 424/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17796059136.0000 - mse: 17796059136.0000 - val_loss: 17362028544.0000 - val_mse: 17362028544.0000\n",
      "Epoch 425/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17795710976.0000 - mse: 17795710976.0000 - val_loss: 17361696768.0000 - val_mse: 17361696768.0000\n",
      "Epoch 426/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17795350528.0000 - mse: 17795350528.0000 - val_loss: 17361340416.0000 - val_mse: 17361340416.0000\n",
      "Epoch 427/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17794983936.0000 - mse: 17794983936.0000 - val_loss: 17360957440.0000 - val_mse: 17360957440.0000\n",
      "Epoch 428/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17794631680.0000 - mse: 17794631680.0000 - val_loss: 17360605184.0000 - val_mse: 17360605184.0000\n",
      "Epoch 429/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17794267136.0000 - mse: 17794267136.0000 - val_loss: 17360273408.0000 - val_mse: 17360273408.0000\n",
      "Epoch 430/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17793890304.0000 - mse: 17793890304.0000 - val_loss: 17359896576.0000 - val_mse: 17359896576.0000\n",
      "Epoch 431/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17793542144.0000 - mse: 17793542144.0000 - val_loss: 17359538176.0000 - val_mse: 17359538176.0000\n",
      "Epoch 432/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17793185792.0000 - mse: 17793185792.0000 - val_loss: 17359202304.0000 - val_mse: 17359202304.0000\n",
      "Epoch 433/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17792831488.0000 - mse: 17792831488.0000 - val_loss: 17358819328.0000 - val_mse: 17358819328.0000\n",
      "Epoch 434/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17792483328.0000 - mse: 17792483328.0000 - val_loss: 17358481408.0000 - val_mse: 17358481408.0000\n",
      "Epoch 435/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17792096256.0000 - mse: 17792096256.0000 - val_loss: 17358131200.0000 - val_mse: 17358131200.0000\n",
      "Epoch 436/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17791750144.0000 - mse: 17791750144.0000 - val_loss: 17357758464.0000 - val_mse: 17357758464.0000\n",
      "Epoch 437/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17791371264.0000 - mse: 17791371264.0000 - val_loss: 17357410304.0000 - val_mse: 17357410304.0000\n",
      "Epoch 438/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17791025152.0000 - mse: 17791025152.0000 - val_loss: 17357043712.0000 - val_mse: 17357043712.0000\n",
      "Epoch 439/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17790668800.0000 - mse: 17790668800.0000 - val_loss: 17356685312.0000 - val_mse: 17356685312.0000\n",
      "Epoch 440/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17790316544.0000 - mse: 17790316544.0000 - val_loss: 17356357632.0000 - val_mse: 17356357632.0000\n",
      "Epoch 441/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17789945856.0000 - mse: 17789945856.0000 - val_loss: 17355974656.0000 - val_mse: 17355974656.0000\n",
      "Epoch 442/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17789589504.0000 - mse: 17789589504.0000 - val_loss: 17355622400.0000 - val_mse: 17355622400.0000\n",
      "Epoch 443/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17789227008.0000 - mse: 17789227008.0000 - val_loss: 17355282432.0000 - val_mse: 17355282432.0000\n",
      "Epoch 444/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17788870656.0000 - mse: 17788870656.0000 - val_loss: 17354907648.0000 - val_mse: 17354907648.0000\n",
      "Epoch 445/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17788516352.0000 - mse: 17788516352.0000 - val_loss: 17354559488.0000 - val_mse: 17354559488.0000\n",
      "Epoch 446/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17788160000.0000 - mse: 17788160000.0000 - val_loss: 17354196992.0000 - val_mse: 17354196992.0000\n",
      "Epoch 447/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17787803648.0000 - mse: 17787803648.0000 - val_loss: 17353836544.0000 - val_mse: 17353836544.0000\n",
      "Epoch 448/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17787430912.0000 - mse: 17787430912.0000 - val_loss: 17353488384.0000 - val_mse: 17353488384.0000\n",
      "Epoch 449/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17787072512.0000 - mse: 17787072512.0000 - val_loss: 17353138176.0000 - val_mse: 17353138176.0000\n",
      "Epoch 450/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17786714112.0000 - mse: 17786714112.0000 - val_loss: 17352763392.0000 - val_mse: 17352763392.0000\n",
      "Epoch 451/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17786318848.0000 - mse: 17786318848.0000 - val_loss: 17352417280.0000 - val_mse: 17352417280.0000\n",
      "Epoch 452/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17785982976.0000 - mse: 17785982976.0000 - val_loss: 17352073216.0000 - val_mse: 17352073216.0000\n",
      "Epoch 453/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17785630720.0000 - mse: 17785630720.0000 - val_loss: 17351700480.0000 - val_mse: 17351700480.0000\n",
      "Epoch 454/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17785262080.0000 - mse: 17785262080.0000 - val_loss: 17351342080.0000 - val_mse: 17351342080.0000\n",
      "Epoch 455/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17784905728.0000 - mse: 17784905728.0000 - val_loss: 17351006208.0000 - val_mse: 17351006208.0000\n",
      "Epoch 456/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17784547328.0000 - mse: 17784547328.0000 - val_loss: 17350627328.0000 - val_mse: 17350627328.0000\n",
      "Epoch 457/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17784182784.0000 - mse: 17784182784.0000 - val_loss: 17350266880.0000 - val_mse: 17350266880.0000\n",
      "Epoch 458/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17783834624.0000 - mse: 17783834624.0000 - val_loss: 17349943296.0000 - val_mse: 17349943296.0000\n",
      "Epoch 459/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17783465984.0000 - mse: 17783465984.0000 - val_loss: 17349566464.0000 - val_mse: 17349566464.0000\n",
      "Epoch 460/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17783099392.0000 - mse: 17783099392.0000 - val_loss: 17349193728.0000 - val_mse: 17349193728.0000\n",
      "Epoch 461/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17782747136.0000 - mse: 17782747136.0000 - val_loss: 17348861952.0000 - val_mse: 17348861952.0000\n",
      "Epoch 462/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17782390784.0000 - mse: 17782390784.0000 - val_loss: 17348491264.0000 - val_mse: 17348491264.0000\n",
      "Epoch 463/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17782032384.0000 - mse: 17782032384.0000 - val_loss: 17348130816.0000 - val_mse: 17348130816.0000\n",
      "Epoch 464/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17781680128.0000 - mse: 17781680128.0000 - val_loss: 17347786752.0000 - val_mse: 17347786752.0000\n",
      "Epoch 465/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17781311488.0000 - mse: 17781311488.0000 - val_loss: 17347420160.0000 - val_mse: 17347420160.0000\n",
      "Epoch 466/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17780940800.0000 - mse: 17780940800.0000 - val_loss: 17347078144.0000 - val_mse: 17347078144.0000\n",
      "Epoch 467/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17780584448.0000 - mse: 17780584448.0000 - val_loss: 17346713600.0000 - val_mse: 17346713600.0000\n",
      "Epoch 468/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17780238336.0000 - mse: 17780238336.0000 - val_loss: 17346355200.0000 - val_mse: 17346355200.0000\n",
      "Epoch 469/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17779871744.0000 - mse: 17779871744.0000 - val_loss: 17346002944.0000 - val_mse: 17346002944.0000\n",
      "Epoch 470/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17779505152.0000 - mse: 17779505152.0000 - val_loss: 17345644544.0000 - val_mse: 17345644544.0000\n",
      "Epoch 471/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17779154944.0000 - mse: 17779154944.0000 - val_loss: 17345292288.0000 - val_mse: 17345292288.0000\n",
      "Epoch 472/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17778796544.0000 - mse: 17778796544.0000 - val_loss: 17344921600.0000 - val_mse: 17344921600.0000\n",
      "Epoch 473/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17778423808.0000 - mse: 17778423808.0000 - val_loss: 17344579584.0000 - val_mse: 17344579584.0000\n",
      "Epoch 474/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17778061312.0000 - mse: 17778061312.0000 - val_loss: 17344235520.0000 - val_mse: 17344235520.0000\n",
      "Epoch 475/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17777709056.0000 - mse: 17777709056.0000 - val_loss: 17343866880.0000 - val_mse: 17343866880.0000\n",
      "Epoch 476/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17777346560.0000 - mse: 17777346560.0000 - val_loss: 17343502336.0000 - val_mse: 17343502336.0000\n",
      "Epoch 477/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17776977920.0000 - mse: 17776977920.0000 - val_loss: 17343162368.0000 - val_mse: 17343162368.0000\n",
      "Epoch 478/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17776648192.0000 - mse: 17776648192.0000 - val_loss: 17342787584.0000 - val_mse: 17342787584.0000\n",
      "Epoch 479/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17776254976.0000 - mse: 17776254976.0000 - val_loss: 17342433280.0000 - val_mse: 17342433280.0000\n",
      "Epoch 480/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17775912960.0000 - mse: 17775912960.0000 - val_loss: 17342085120.0000 - val_mse: 17342085120.0000\n",
      "Epoch 481/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17775540224.0000 - mse: 17775540224.0000 - val_loss: 17341734912.0000 - val_mse: 17341734912.0000\n",
      "Epoch 482/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17775183872.0000 - mse: 17775183872.0000 - val_loss: 17341366272.0000 - val_mse: 17341366272.0000\n",
      "Epoch 483/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17774831616.0000 - mse: 17774831616.0000 - val_loss: 17341022208.0000 - val_mse: 17341022208.0000\n",
      "Epoch 484/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17774477312.0000 - mse: 17774477312.0000 - val_loss: 17340657664.0000 - val_mse: 17340657664.0000\n",
      "Epoch 485/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17774106624.0000 - mse: 17774106624.0000 - val_loss: 17340301312.0000 - val_mse: 17340301312.0000\n",
      "Epoch 486/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17773740032.0000 - mse: 17773740032.0000 - val_loss: 17339944960.0000 - val_mse: 17339944960.0000\n",
      "Epoch 487/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17773383680.0000 - mse: 17773383680.0000 - val_loss: 17339586560.0000 - val_mse: 17339586560.0000\n",
      "Epoch 488/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17773041664.0000 - mse: 17773041664.0000 - val_loss: 17339230208.0000 - val_mse: 17339230208.0000\n",
      "Epoch 489/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17772658688.0000 - mse: 17772658688.0000 - val_loss: 17338886144.0000 - val_mse: 17338886144.0000\n",
      "Epoch 490/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17772298240.0000 - mse: 17772298240.0000 - val_loss: 17338511360.0000 - val_mse: 17338511360.0000\n",
      "Epoch 491/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17771960320.0000 - mse: 17771960320.0000 - val_loss: 17338167296.0000 - val_mse: 17338167296.0000\n",
      "Epoch 492/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17771612160.0000 - mse: 17771612160.0000 - val_loss: 17337821184.0000 - val_mse: 17337821184.0000\n",
      "Epoch 493/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17771235328.0000 - mse: 17771235328.0000 - val_loss: 17337450496.0000 - val_mse: 17337450496.0000\n",
      "Epoch 494/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17770891264.0000 - mse: 17770891264.0000 - val_loss: 17337098240.0000 - val_mse: 17337098240.0000\n",
      "Epoch 495/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17770524672.0000 - mse: 17770524672.0000 - val_loss: 17336745984.0000 - val_mse: 17336745984.0000\n",
      "Epoch 496/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17770162176.0000 - mse: 17770162176.0000 - val_loss: 17336383488.0000 - val_mse: 17336383488.0000\n",
      "Epoch 497/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17769789440.0000 - mse: 17769789440.0000 - val_loss: 17336029184.0000 - val_mse: 17336029184.0000\n",
      "Epoch 498/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17769424896.0000 - mse: 17769424896.0000 - val_loss: 17335672832.0000 - val_mse: 17335672832.0000\n",
      "Epoch 499/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17769086976.0000 - mse: 17769086976.0000 - val_loss: 17335310336.0000 - val_mse: 17335310336.0000\n",
      "Epoch 500/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17768730624.0000 - mse: 17768730624.0000 - val_loss: 17334956032.0000 - val_mse: 17334956032.0000\n",
      "Epoch 501/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17768351744.0000 - mse: 17768351744.0000 - val_loss: 17334605824.0000 - val_mse: 17334605824.0000\n",
      "Epoch 502/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17768003584.0000 - mse: 17768003584.0000 - val_loss: 17334253568.0000 - val_mse: 17334253568.0000\n",
      "Epoch 503/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17767628800.0000 - mse: 17767628800.0000 - val_loss: 17333897216.0000 - val_mse: 17333897216.0000\n",
      "Epoch 504/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17767284736.0000 - mse: 17767284736.0000 - val_loss: 17333538816.0000 - val_mse: 17333538816.0000\n",
      "Epoch 505/600\n",
      "1872/1872 [==============================] - 9s 5ms/step - loss: 17766934528.0000 - mse: 17766934528.0000 - val_loss: 17333188608.0000 - val_mse: 17333188608.0000\n",
      "Epoch 506/600\n",
      "1872/1872 [==============================] - 9s 5ms/step - loss: 17766553600.0000 - mse: 17766553600.0000 - val_loss: 17332817920.0000 - val_mse: 17332817920.0000\n",
      "Epoch 507/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17766211584.0000 - mse: 17766211584.0000 - val_loss: 17332471808.0000 - val_mse: 17332471808.0000\n",
      "Epoch 508/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17765834752.0000 - mse: 17765834752.0000 - val_loss: 17332111360.0000 - val_mse: 17332111360.0000\n",
      "Epoch 509/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17765488640.0000 - mse: 17765488640.0000 - val_loss: 17331771392.0000 - val_mse: 17331771392.0000\n",
      "Epoch 510/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17765115904.0000 - mse: 17765115904.0000 - val_loss: 17331404800.0000 - val_mse: 17331404800.0000\n",
      "Epoch 511/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17764773888.0000 - mse: 17764773888.0000 - val_loss: 17331042304.0000 - val_mse: 17331042304.0000\n",
      "Epoch 512/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17764407296.0000 - mse: 17764407296.0000 - val_loss: 17330683904.0000 - val_mse: 17330683904.0000\n",
      "Epoch 513/600\n",
      "1872/1872 [==============================] - 8s 4ms/step - loss: 17764048896.0000 - mse: 17764048896.0000 - val_loss: 17330327552.0000 - val_mse: 17330327552.0000\n",
      "Epoch 514/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17763696640.0000 - mse: 17763696640.0000 - val_loss: 17329983488.0000 - val_mse: 17329983488.0000\n",
      "Epoch 515/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17763344384.0000 - mse: 17763344384.0000 - val_loss: 17329627136.0000 - val_mse: 17329627136.0000\n",
      "Epoch 516/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17762975744.0000 - mse: 17762975744.0000 - val_loss: 17329266688.0000 - val_mse: 17329266688.0000\n",
      "Epoch 517/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17762598912.0000 - mse: 17762598912.0000 - val_loss: 17328906240.0000 - val_mse: 17328906240.0000\n",
      "Epoch 518/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17762244608.0000 - mse: 17762244608.0000 - val_loss: 17328568320.0000 - val_mse: 17328568320.0000\n",
      "Epoch 519/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17761912832.0000 - mse: 17761912832.0000 - val_loss: 17328187392.0000 - val_mse: 17328187392.0000\n",
      "Epoch 520/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17761525760.0000 - mse: 17761525760.0000 - val_loss: 17327845376.0000 - val_mse: 17327845376.0000\n",
      "Epoch 521/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17761169408.0000 - mse: 17761169408.0000 - val_loss: 17327491072.0000 - val_mse: 17327491072.0000\n",
      "Epoch 522/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17760827392.0000 - mse: 17760827392.0000 - val_loss: 17327130624.0000 - val_mse: 17327130624.0000\n",
      "Epoch 523/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17760466944.0000 - mse: 17760466944.0000 - val_loss: 17326757888.0000 - val_mse: 17326757888.0000\n",
      "Epoch 524/600\n",
      "1872/1872 [==============================] - 7s 4ms/step - loss: 17760090112.0000 - mse: 17760090112.0000 - val_loss: 17326424064.0000 - val_mse: 17326424064.0000\n",
      "Epoch 525/600\n",
      "1872/1872 [==============================] - 7s 3ms/step - loss: 17759733760.0000 - mse: 17759733760.0000 - val_loss: 17326067712.0000 - val_mse: 17326067712.0000\n",
      "Epoch 526/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17759375360.0000 - mse: 17759375360.0000 - val_loss: 17325694976.0000 - val_mse: 17325694976.0000\n",
      "Epoch 527/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17759010816.0000 - mse: 17759010816.0000 - val_loss: 17325357056.0000 - val_mse: 17325357056.0000\n",
      "Epoch 528/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17758660608.0000 - mse: 17758660608.0000 - val_loss: 17324998656.0000 - val_mse: 17324998656.0000\n",
      "Epoch 529/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17758289920.0000 - mse: 17758289920.0000 - val_loss: 17324632064.0000 - val_mse: 17324632064.0000\n",
      "Epoch 530/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17757945856.0000 - mse: 17757945856.0000 - val_loss: 17324288000.0000 - val_mse: 17324288000.0000\n",
      "Epoch 531/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17757585408.0000 - mse: 17757585408.0000 - val_loss: 17323935744.0000 - val_mse: 17323935744.0000\n",
      "Epoch 532/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17757220864.0000 - mse: 17757220864.0000 - val_loss: 17323556864.0000 - val_mse: 17323556864.0000\n",
      "Epoch 533/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17756870656.0000 - mse: 17756870656.0000 - val_loss: 17323220992.0000 - val_mse: 17323220992.0000\n",
      "Epoch 534/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17756526592.0000 - mse: 17756526592.0000 - val_loss: 17322866688.0000 - val_mse: 17322866688.0000\n",
      "Epoch 535/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17756145664.0000 - mse: 17756145664.0000 - val_loss: 17322500096.0000 - val_mse: 17322500096.0000\n",
      "Epoch 536/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17755793408.0000 - mse: 17755793408.0000 - val_loss: 17322143744.0000 - val_mse: 17322143744.0000\n",
      "Epoch 537/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17755416576.0000 - mse: 17755416576.0000 - val_loss: 17321809920.0000 - val_mse: 17321809920.0000\n",
      "Epoch 538/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17755058176.0000 - mse: 17755058176.0000 - val_loss: 17321433088.0000 - val_mse: 17321433088.0000\n",
      "Epoch 539/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17754707968.0000 - mse: 17754707968.0000 - val_loss: 17321082880.0000 - val_mse: 17321082880.0000\n",
      "Epoch 540/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17754345472.0000 - mse: 17754345472.0000 - val_loss: 17320722432.0000 - val_mse: 17320722432.0000\n",
      "Epoch 541/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17753978880.0000 - mse: 17753978880.0000 - val_loss: 17320376320.0000 - val_mse: 17320376320.0000\n",
      "Epoch 542/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17753626624.0000 - mse: 17753626624.0000 - val_loss: 17320007680.0000 - val_mse: 17320007680.0000\n",
      "Epoch 543/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17753276416.0000 - mse: 17753276416.0000 - val_loss: 17319653376.0000 - val_mse: 17319653376.0000\n",
      "Epoch 544/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17752903680.0000 - mse: 17752903680.0000 - val_loss: 17319309312.0000 - val_mse: 17319309312.0000\n",
      "Epoch 545/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17752547328.0000 - mse: 17752547328.0000 - val_loss: 17318948864.0000 - val_mse: 17318948864.0000\n",
      "Epoch 546/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17752203264.0000 - mse: 17752203264.0000 - val_loss: 17318592512.0000 - val_mse: 17318592512.0000\n",
      "Epoch 547/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17751838720.0000 - mse: 17751838720.0000 - val_loss: 17318238208.0000 - val_mse: 17318238208.0000\n",
      "Epoch 548/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17751461888.0000 - mse: 17751461888.0000 - val_loss: 17317881856.0000 - val_mse: 17317881856.0000\n",
      "Epoch 549/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17751126016.0000 - mse: 17751126016.0000 - val_loss: 17317523456.0000 - val_mse: 17317523456.0000\n",
      "Epoch 550/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17750738944.0000 - mse: 17750738944.0000 - val_loss: 17317158912.0000 - val_mse: 17317158912.0000\n",
      "Epoch 551/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17750423552.0000 - mse: 17750423552.0000 - val_loss: 17316814848.0000 - val_mse: 17316814848.0000\n",
      "Epoch 552/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17750048768.0000 - mse: 17750048768.0000 - val_loss: 17316456448.0000 - val_mse: 17316456448.0000\n",
      "Epoch 553/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17749657600.0000 - mse: 17749657600.0000 - val_loss: 17316093952.0000 - val_mse: 17316093952.0000\n",
      "Epoch 554/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17749313536.0000 - mse: 17749313536.0000 - val_loss: 17315743744.0000 - val_mse: 17315743744.0000\n",
      "Epoch 555/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17748963328.0000 - mse: 17748963328.0000 - val_loss: 17315399680.0000 - val_mse: 17315399680.0000\n",
      "Epoch 556/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17748619264.0000 - mse: 17748619264.0000 - val_loss: 17315035136.0000 - val_mse: 17315035136.0000\n",
      "Epoch 557/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17748238336.0000 - mse: 17748238336.0000 - val_loss: 17314686976.0000 - val_mse: 17314686976.0000\n",
      "Epoch 558/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17747877888.0000 - mse: 17747877888.0000 - val_loss: 17314324480.0000 - val_mse: 17314324480.0000\n",
      "Epoch 559/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17747531776.0000 - mse: 17747531776.0000 - val_loss: 17313972224.0000 - val_mse: 17313972224.0000\n",
      "Epoch 560/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17747173376.0000 - mse: 17747173376.0000 - val_loss: 17313619968.0000 - val_mse: 17313619968.0000\n",
      "Epoch 561/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17746806784.0000 - mse: 17746806784.0000 - val_loss: 17313247232.0000 - val_mse: 17313247232.0000\n",
      "Epoch 562/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17746436096.0000 - mse: 17746436096.0000 - val_loss: 17312913408.0000 - val_mse: 17312913408.0000\n",
      "Epoch 563/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17746100224.0000 - mse: 17746100224.0000 - val_loss: 17312550912.0000 - val_mse: 17312550912.0000\n",
      "Epoch 564/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17745745920.0000 - mse: 17745745920.0000 - val_loss: 17312176128.0000 - val_mse: 17312176128.0000\n",
      "Epoch 565/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17745381376.0000 - mse: 17745381376.0000 - val_loss: 17311844352.0000 - val_mse: 17311844352.0000\n",
      "Epoch 566/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17745014784.0000 - mse: 17745014784.0000 - val_loss: 17311488000.0000 - val_mse: 17311488000.0000\n",
      "Epoch 567/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17744666624.0000 - mse: 17744666624.0000 - val_loss: 17311127552.0000 - val_mse: 17311127552.0000\n",
      "Epoch 568/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17744293888.0000 - mse: 17744293888.0000 - val_loss: 17310769152.0000 - val_mse: 17310769152.0000\n",
      "Epoch 569/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17743935488.0000 - mse: 17743935488.0000 - val_loss: 17310443520.0000 - val_mse: 17310443520.0000\n",
      "Epoch 570/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17743585280.0000 - mse: 17743585280.0000 - val_loss: 17310052352.0000 - val_mse: 17310052352.0000\n",
      "Epoch 571/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17743222784.0000 - mse: 17743222784.0000 - val_loss: 17309716480.0000 - val_mse: 17309716480.0000\n",
      "Epoch 572/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17742872576.0000 - mse: 17742872576.0000 - val_loss: 17309364224.0000 - val_mse: 17309364224.0000\n",
      "Epoch 573/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17742508032.0000 - mse: 17742508032.0000 - val_loss: 17309003776.0000 - val_mse: 17309003776.0000\n",
      "Epoch 574/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17742159872.0000 - mse: 17742159872.0000 - val_loss: 17308659712.0000 - val_mse: 17308659712.0000\n",
      "Epoch 575/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17741803520.0000 - mse: 17741803520.0000 - val_loss: 17308299264.0000 - val_mse: 17308299264.0000\n",
      "Epoch 576/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17741443072.0000 - mse: 17741443072.0000 - val_loss: 17307936768.0000 - val_mse: 17307936768.0000\n",
      "Epoch 577/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17741074432.0000 - mse: 17741074432.0000 - val_loss: 17307588608.0000 - val_mse: 17307588608.0000\n",
      "Epoch 578/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17740728320.0000 - mse: 17740728320.0000 - val_loss: 17307234304.0000 - val_mse: 17307234304.0000\n",
      "Epoch 579/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17740353536.0000 - mse: 17740353536.0000 - val_loss: 17306871808.0000 - val_mse: 17306871808.0000\n",
      "Epoch 580/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17740009472.0000 - mse: 17740009472.0000 - val_loss: 17306515456.0000 - val_mse: 17306515456.0000\n",
      "Epoch 581/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17739657216.0000 - mse: 17739657216.0000 - val_loss: 17306165248.0000 - val_mse: 17306165248.0000\n",
      "Epoch 582/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17739290624.0000 - mse: 17739290624.0000 - val_loss: 17305808896.0000 - val_mse: 17305808896.0000\n",
      "Epoch 583/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17738913792.0000 - mse: 17738913792.0000 - val_loss: 17305458688.0000 - val_mse: 17305458688.0000\n",
      "Epoch 584/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17738577920.0000 - mse: 17738577920.0000 - val_loss: 17305094144.0000 - val_mse: 17305094144.0000\n",
      "Epoch 585/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17738194944.0000 - mse: 17738194944.0000 - val_loss: 17304756224.0000 - val_mse: 17304756224.0000\n",
      "Epoch 586/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17737865216.0000 - mse: 17737865216.0000 - val_loss: 17304393728.0000 - val_mse: 17304393728.0000\n",
      "Epoch 587/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17737500672.0000 - mse: 17737500672.0000 - val_loss: 17304035328.0000 - val_mse: 17304035328.0000\n",
      "Epoch 588/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17737154560.0000 - mse: 17737154560.0000 - val_loss: 17303683072.0000 - val_mse: 17303683072.0000\n",
      "Epoch 589/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17736777728.0000 - mse: 17736777728.0000 - val_loss: 17303336960.0000 - val_mse: 17303336960.0000\n",
      "Epoch 590/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17736423424.0000 - mse: 17736423424.0000 - val_loss: 17302962176.0000 - val_mse: 17302962176.0000\n",
      "Epoch 591/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17736052736.0000 - mse: 17736052736.0000 - val_loss: 17302622208.0000 - val_mse: 17302622208.0000\n",
      "Epoch 592/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17735714816.0000 - mse: 17735714816.0000 - val_loss: 17302274048.0000 - val_mse: 17302274048.0000\n",
      "Epoch 593/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17735364608.0000 - mse: 17735364608.0000 - val_loss: 17301895168.0000 - val_mse: 17301895168.0000\n",
      "Epoch 594/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17734977536.0000 - mse: 17734977536.0000 - val_loss: 17301549056.0000 - val_mse: 17301549056.0000\n",
      "Epoch 595/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17734617088.0000 - mse: 17734617088.0000 - val_loss: 17301204992.0000 - val_mse: 17301204992.0000\n",
      "Epoch 596/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17734275072.0000 - mse: 17734275072.0000 - val_loss: 17300844544.0000 - val_mse: 17300844544.0000\n",
      "Epoch 597/600\n",
      "1872/1872 [==============================] - 5s 3ms/step - loss: 17733918720.0000 - mse: 17733918720.0000 - val_loss: 17300484096.0000 - val_mse: 17300484096.0000\n",
      "Epoch 598/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17733572608.0000 - mse: 17733572608.0000 - val_loss: 17300129792.0000 - val_mse: 17300129792.0000\n",
      "Epoch 599/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17733189632.0000 - mse: 17733189632.0000 - val_loss: 17299771392.0000 - val_mse: 17299771392.0000\n",
      "Epoch 600/600\n",
      "1872/1872 [==============================] - 6s 3ms/step - loss: 17732837376.0000 - mse: 17732837376.0000 - val_loss: 17299427328.0000 - val_mse: 17299427328.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161bb7b7f70>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=600,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test,y_test),callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6e70022",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "922/922 [==============================] - 2s 2ms/step\n",
      "96221.5113151152\n",
      "17299421754.664093\n",
      "-1.1514439217792405\n"
     ]
    }
   ],
   "source": [
    "P36=model1.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test,P36))\n",
    "print(mean_squared_error(y_test,P36))\n",
    "print(r2_score(y_test,P36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e10a1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(M10, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
